{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584d6bcb",
   "metadata": {
    "papermill": {
     "duration": 0.005179,
     "end_time": "2026-01-23T17:32:36.170035",
     "exception": false,
     "start_time": "2026-01-23T17:32:36.164856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing & Loading Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73179156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:32:36.180664Z",
     "iopub.status.busy": "2026-01-23T17:32:36.180299Z",
     "iopub.status.idle": "2026-01-23T17:33:47.435031Z",
     "shell.execute_reply": "2026-01-23T17:33:47.434075Z"
    },
    "papermill": {
     "duration": 71.262725,
     "end_time": "2026-01-23T17:33:47.437277",
     "exception": false,
     "start_time": "2026-01-23T17:32:36.174552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\r\n",
      "Requirement already satisfied: torch==2.4.0 in /opt/conda/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: torchvision==0.19.0 in /opt/conda/lib/python3.10/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: torchaudio==2.4.0 in /opt/conda/lib/python3.10/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (2024.6.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.19.0) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.0) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.0) (1.3.0)\r\n",
      "Collecting monai==1.3.2 (from monai[nibabel]==1.3.2)\r\n",
      "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: monai\r\n",
      "Successfully installed monai-1.3.2\r\n",
      "Found existing installation: jax 0.4.26\r\n",
      "Uninstalling jax-0.4.26:\r\n",
      "  Successfully uninstalled jax-0.4.26\r\n",
      "Found existing installation: jaxlib 0.4.26.dev20240620\r\n",
      "Uninstalling jaxlib-0.4.26.dev20240620:\r\n",
      "  Successfully uninstalled jaxlib-0.4.26.dev20240620\r\n",
      "Collecting pennylane\r\n",
      "  Downloading pennylane-0.42.3-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.14.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pennylane) (3.3)\r\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\r\n",
      "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting autograd (from pennylane)\r\n",
      "  Downloading autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.4.4)\r\n",
      "Collecting autoray<0.8,>=0.6.11 (from pennylane)\r\n",
      "  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.2.4)\r\n",
      "Collecting pennylane-lightning>=0.42 (from pennylane)\r\n",
      "  Downloading pennylane_lightning-0.42.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pennylane) (2.32.3)\r\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.13.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.12.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pennylane) (21.3)\r\n",
      "Collecting diastatic-malt (from pennylane)\r\n",
      "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.26.4)\r\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.42->pennylane)\r\n",
      "  Downloading scipy_openblas32-0.3.31.22.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: astunparse in /opt/conda/lib/python3.10/site-packages (from diastatic-malt->pennylane) (1.6.3)\r\n",
      "Requirement already satisfied: gast in /opt/conda/lib/python3.10/site-packages (from diastatic-malt->pennylane) (0.5.4)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from diastatic-malt->pennylane) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pennylane) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (2024.8.30)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse->diastatic-malt->pennylane) (0.43.0)\r\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from astunparse->diastatic-malt->pennylane) (1.16.0)\r\n",
      "Downloading pennylane-0.42.3-py3-none-any.whl (4.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autoray-0.7.2-py3-none-any.whl (930 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pennylane_lightning-0.42.0-cp310-cp310-manylinux_2_28_x86_64.whl (2.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autograd-1.8.0-py3-none-any.whl (51 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy_openblas32-0.3.31.22.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scipy-openblas32, rustworkx, autoray, autograd, diastatic-malt, pennylane-lightning, pennylane\r\n",
      "Successfully installed autograd-1.8.0 autoray-0.7.2 diastatic-malt-2.15.2 pennylane-0.42.3 pennylane-lightning-0.42.0 rustworkx-0.17.1 scipy-openblas32-0.3.31.22.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "# --- 1. INSTALLATION (Crucial Fix) ---\n",
    "# We upgrade torchvision so it matches the new PyTorch version installed by MONAI\n",
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install \"monai[nibabel]==1.3.2\" --no-deps\n",
    "# Remove JAX to stop PennyLane from trying to import it\n",
    "!pip uninstall jax jaxlib -y\n",
    "!pip install pennylane\n",
    "# --- 2. IMPORTS (Cleaned up duplicates) ---\n",
    "import pennylane as qml\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import pdb\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision \n",
    "\n",
    "# MONAI Imports\n",
    "from monai.transforms import (\n",
    "    LoadImage, Compose, NormalizeIntensityd, RandSpatialCropd, RandFlipd,\n",
    "    RandRotate90d, Rand3DElasticd, RandAdjustContrastd, CenterSpatialCropd,\n",
    "    Resized, RandRotated, RandZoomd, RandGaussianNoised, Spacingd, \n",
    "    RandShiftIntensityd, CropForegroundd, SpatialPadd, AsDiscrete, GridPatchd\n",
    ")\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.networks import one_hot\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "# Other\n",
    "from grpc import insecure_channel\n",
    "from ipywidgets import interact, IntSlider\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faee386",
   "metadata": {
    "papermill": {
     "duration": 0.005763,
     "end_time": "2026-01-23T17:33:47.450827",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.445064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Dataset with Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd8cf24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.464565Z",
     "iopub.status.busy": "2026-01-23T17:33:47.463822Z",
     "iopub.status.idle": "2026-01-23T17:33:47.480107Z",
     "shell.execute_reply": "2026-01-23T17:33:47.479314Z"
    },
    "papermill": {
     "duration": 0.024927,
     "end_time": "2026-01-23T17:33:47.481596",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.456669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset3D(Dataset):\n",
    "    def __init__(self, data_dir, patient_lists, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.patient_lists = patient_lists\n",
    "        self.mode = mode\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_with_aspect_ratio(keys, target_size):\n",
    "        def transform(data):\n",
    "            for key in keys:\n",
    "                volume = data[key]\n",
    "                original_shape = volume.shape[-3:]\n",
    "    \n",
    "                scaling_factor = min(\n",
    "                    target_size[0] / original_shape[0],\n",
    "                    target_size[1] / original_shape[1],\n",
    "                    target_size[2] / original_shape[2]\n",
    "                )\n",
    "    \n",
    "                # Computing the intermediate size while preserving aspect ratio\n",
    "                new_shape = [\n",
    "                    int(dim * scaling_factor) for dim in original_shape\n",
    "                ]\n",
    "    \n",
    "                # Resizing to the intermediate shape\n",
    "                resize_transform = Resized(keys=[key], spatial_size=new_shape, mode=\"trilinear\" if key == \"imgs\" else \"nearest-exact\")\n",
    "                data = resize_transform(data)\n",
    "    \n",
    "                # Padding to the final target size\n",
    "                pad_transform = SpatialPadd(keys=[key], spatial_size=target_size, mode=\"constant\")\n",
    "                data = pad_transform(data)\n",
    "            return data\n",
    "\n",
    "        return transform\n",
    "    \n",
    "    def preprocess(cls, data, mode):\n",
    "        if mode == 'training':\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True),\n",
    "              \n",
    "            RandFlipd(keys=[\"imgs\", \"masks\"],   \n",
    "                    prob=0.5,                 \n",
    "                    spatial_axis=2,  \n",
    "            ),\n",
    "\n",
    "            RandAdjustContrastd(\n",
    "                keys=[\"imgs\"],          \n",
    "                prob=0.15,             \n",
    "                gamma=(0.65, 1.5),   \n",
    "            ),\n",
    "            \n",
    "        ])\n",
    "\n",
    "        elif mode == 'validation':\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True)\n",
    "\n",
    "        ])\n",
    "\n",
    "        else: # 'testing'\n",
    "          transform = Compose([\n",
    "            CropForegroundd(keys=[\"imgs\", \"masks\"], source_key=\"imgs\"),\n",
    "            cls.resize_with_aspect_ratio(keys=[\"imgs\", \"masks\"], target_size=[128, 128, 128]),\n",
    "            NormalizeIntensityd( keys=['imgs'], nonzero=False, channel_wise=True)\n",
    "\n",
    "        ])\n",
    "\n",
    "        augmented_data = transform(data)\n",
    "        return augmented_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_lists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_lists[idx]\n",
    "        loadimage = LoadImage(reader='NibabelReader', image_only=True)\n",
    "\n",
    "        patient_folder_path = os.path.join(self.data_dir, patient_id)\n",
    "\n",
    "        def resolve_file_path(folder, name):\n",
    "            file_path = os.path.join(folder, name)\n",
    "            # Check if the given path is a directory (case with 4 subdirs)\n",
    "            if os.path.isdir(file_path):\n",
    "                # Find the first file inside the directory that ends with .nii\n",
    "                for root, _, files in os.walk(file_path):\n",
    "                    for file in files:\n",
    "                        if file.endswith(\".nii\"):\n",
    "                            return os.path.join(root, file)\n",
    "            return file_path\n",
    "\n",
    "\n",
    "        # Resolve paths for all required image types\n",
    "        t1c_path  = resolve_file_path(patient_folder_path, patient_id + '-t1c.nii')\n",
    "        t1n_path  = resolve_file_path(patient_folder_path, patient_id + '-t1n.nii')\n",
    "        t2f_path  = resolve_file_path(patient_folder_path, patient_id + '-t2f.nii')\n",
    "        t2w_path  = resolve_file_path(patient_folder_path, patient_id + '-t2w.nii')\n",
    "        seg_path  = os.path.join(patient_folder_path, patient_id + '-seg.nii')\n",
    "\n",
    "        t1c_loader   = loadimage( t1c_path )\n",
    "        t1n_loader   = loadimage( t1n_path )\n",
    "        t2f_loader   = loadimage( t2f_path )\n",
    "        t2w_loader   = loadimage( t2w_path )\n",
    "        masks_loader = loadimage( seg_path )\n",
    "\n",
    "        # Make the dimension of channel\n",
    "        t1c_tensor   = torch.Tensor(t1c_loader).unsqueeze(0)\n",
    "        t1n_tensor   = torch.Tensor(t1n_loader).unsqueeze(0)\n",
    "        t2f_tensor   = torch.Tensor(t2f_loader).unsqueeze(0)\n",
    "        t2w_tensor   = torch.Tensor(t2w_loader).unsqueeze(0)\n",
    "        masks_tensor = torch.Tensor(masks_loader).unsqueeze(0)\n",
    "\n",
    "        # dividing the mask to each class\n",
    "        '''\n",
    "        Output channel\n",
    "        [1, 0, 0, 0] = BackGround (BG)\n",
    "        [0, 1, 0, 0] = Necrosis (NE)\n",
    "        [0, 0, 1, 0] = Edema (ED)\n",
    "        [0, 0, 0, 1] = Enhancing Tumor (ET)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # x = torch.ones( masks_tensor.size() )\n",
    "        # y = torch.zeros( masks_tensor.size() )\n",
    "\n",
    "        # masks_BG = torch.where( masks_tensor == 0, x, y )\n",
    "        # masks_NE = torch.where( masks_tensor == 1, x, y )\n",
    "        # masks_ED = torch.where( masks_tensor == 2, x, y )\n",
    "        # masks_ET = torch.where( masks_tensor == 3, x, y )\n",
    "\n",
    "        concat_tensor = torch.cat( (t1c_tensor, t1n_tensor, t2f_tensor, t2w_tensor, masks_tensor), 0 )\n",
    "\n",
    "        data = {\n",
    "            \n",
    "            'imgs'  : np.array(concat_tensor[0:4,:,:,:]),\n",
    "            'masks' : np.array(concat_tensor[4:,:,:,:])\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        augmented_imgs_masks = self.preprocess(data, self.mode)\n",
    "        imgs  = np.array(augmented_imgs_masks['imgs'])\n",
    "        masks = np.array(augmented_imgs_masks['masks'])\n",
    "\n",
    "        y = {\n",
    "\n",
    "            'imgs'  : torch.from_numpy(imgs).type(torch.FloatTensor),\n",
    "            'masks' : torch.from_numpy(masks).type(torch.FloatTensor),\n",
    "            'patient_id' : patient_id\n",
    "\n",
    "        }\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b37c82",
   "metadata": {
    "papermill": {
     "duration": 0.00579,
     "end_time": "2026-01-23T17:33:47.493377",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.487587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9d4b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.506118Z",
     "iopub.status.busy": "2026-01-23T17:33:47.505871Z",
     "iopub.status.idle": "2026-01-23T17:33:47.512766Z",
     "shell.execute_reply": "2026-01-23T17:33:47.512132Z"
    },
    "papermill": {
     "duration": 0.014973,
     "end_time": "2026-01-23T17:33:47.514181",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.499208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(args):\n",
    "    random.seed(5)\n",
    "    split_ratio = {'training': 0.7, 'validation': 0.1, 'testing': 0.2}\n",
    "    data_dir = args['data_dir']\n",
    "    \n",
    "    patient_lists = os.listdir( data_dir )\n",
    "    patient_lists.sort()\n",
    "    total_patients = len(patient_lists)\n",
    "    \n",
    "    # Shuffle the patient list\n",
    "    random.shuffle(patient_lists)\n",
    "    \n",
    "    train_split = int(split_ratio['training'] * total_patients)\n",
    "    val_split = int(split_ratio['validation'] * total_patients)\n",
    "    \n",
    "    train_patient_lists = patient_lists[:train_split]\n",
    "    val_patient_lists = patient_lists[train_split : train_split + val_split]\n",
    "    test_patient_lists = patient_lists[train_split + val_split :]\n",
    "    \n",
    "    train_patient_lists.sort()\n",
    "    val_patient_lists.sort()\n",
    "    test_patient_lists.sort()\n",
    "    \n",
    "    print(f'Number of training samples', len(train_patient_lists))\n",
    "    print(f'Number of validation samples', len(val_patient_lists))\n",
    "    print(f'Number of testing samples', len(test_patient_lists))\n",
    "\n",
    "    trainDataset = CustomDataset3D( data_dir, train_patient_lists, mode='training')\n",
    "    valDataset   = CustomDataset3D( data_dir, val_patient_lists, mode='validation')\n",
    "    testDataset  = CustomDataset3D( data_dir, test_patient_lists, mode='testing')\n",
    "    \n",
    "    trainLoader = DataLoader(\n",
    "        trainDataset, batch_size=args['train_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=True)\n",
    "    \n",
    "    valLoader = DataLoader(\n",
    "        valDataset, batch_size=args['val_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=False)\n",
    "    \n",
    "    testLoader = DataLoader(\n",
    "        testDataset, batch_size=args['test_batch_size'], num_workers=args['workers'], prefetch_factor=2,\n",
    "        pin_memory=True, shuffle=False)\n",
    "\n",
    "    return trainLoader, valLoader, testLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb390d",
   "metadata": {
    "papermill": {
     "duration": 0.00591,
     "end_time": "2026-01-23T17:33:47.526178",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.520268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ac53bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.539417Z",
     "iopub.status.busy": "2026-01-23T17:33:47.539167Z",
     "iopub.status.idle": "2026-01-23T17:33:47.543114Z",
     "shell.execute_reply": "2026-01-23T17:33:47.542490Z"
    },
    "papermill": {
     "duration": 0.012338,
     "end_time": "2026-01-23T17:33:47.544677",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.532339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm  # For a progress bar\n",
    "\n",
    "# args = {\n",
    "#     'workers': 2,\n",
    "#     'epochs': 10,\n",
    "#     'train_batch_size': 1,\n",
    "#     'val_batch_size': 2,\n",
    "#     'test_batch_size': 2,\n",
    "#     'learning_rate': 1e-3,\n",
    "#     'weight_decay': 1e-5,\n",
    "#     'lambd': 0.0051,\n",
    "#     'data_dir': '/kaggle/input/bratsglioma/Training/',\n",
    "#     'in_checkpoint_dir': Path('/kaggle/input/adultgliomamodel-45epochs'),\n",
    "#     'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "# }\n",
    "\n",
    "# trainLoader, valLoader, testLoader = prepare_data_loaders(args)\n",
    "\n",
    "# # Initialize maximum dimensions\n",
    "# max_depth, max_height, max_width = 0, 0, 0\n",
    "\n",
    "# # Loop through trainLoader to find maximum dimensions\n",
    "# for batch in tqdm(trainLoader, desc=\"Calculating max dimensions\"):\n",
    "#     imgs = batch['imgs']  # Extract the images tensor\n",
    "#     _, _, h, w, d = imgs.shape  # Get depth, height, width dimensions\n",
    "#     max_height = max(max_height, h)\n",
    "#     max_width = max(max_width, w)\n",
    "#     max_depth = max(max_depth, d)\n",
    "\n",
    "#     print(f\"Max dimensions: Depth={max_depth}, Height={max_height}, Width={max_width}\")\n",
    "\n",
    "\n",
    "# # Save these dimensions for padding later\n",
    "# max_dimensions = (max_height, max_width, max_depth)\n",
    "# print(f\"Final dimensions: Height={max_height}, Width={max_width}, Depth={max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838d7424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.557907Z",
     "iopub.status.busy": "2026-01-23T17:33:47.557414Z",
     "iopub.status.idle": "2026-01-23T17:33:47.561040Z",
     "shell.execute_reply": "2026-01-23T17:33:47.560342Z"
    },
    "papermill": {
     "duration": 0.011777,
     "end_time": "2026-01-23T17:33:47.562455",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.550678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     'workers': 2,\n",
    "#     'epochs': 10,\n",
    "#     'train_batch_size': 2,\n",
    "#     'val_batch_size': 2,\n",
    "#     'test_batch_size': 2,\n",
    "#     'learning_rate': 1e-3,\n",
    "#     'weight_decay': 1e-5,\n",
    "#     'lambd': 0.0051,\n",
    "#     'data_dir': '/kaggle/input/bratsglioma/Training/',\n",
    "#     'in_checkpoint_dir': Path('/kaggle/input/adultgliomamodel-45epochs'),\n",
    "#     'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "# }\n",
    "\n",
    "# trainLoader, valLoader, testLoader = prepare_data_loaders(args)\n",
    "\n",
    "# for step, y in enumerate( trainLoader ):\n",
    "#   # y_wt, y_tc, y_et = y['masks'] > 0, ((y['masks'] == 1) + (y['masks'] == 3)) > 0, y['masks'] == 3  \n",
    "#   print(y['imgs'].shape)\n",
    "#   print(y['masks'].shape)\n",
    "#   print(y['patient_id'])\n",
    "\n",
    "#   fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "#   for sequence in range(4):\n",
    "#     sequence_data = y['masks'][0][0, :, :, :].cpu().detach().numpy()\n",
    "#     slice_index = 70\n",
    "#     axes[sequence].imshow(sequence_data[:, :, slice_index], cmap='gray', origin='lower')\n",
    "#     axes[sequence].set_title(f'Sequence {sequence + 1}')\n",
    "\n",
    "#   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28abaca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.575548Z",
     "iopub.status.busy": "2026-01-23T17:33:47.575286Z",
     "iopub.status.idle": "2026-01-23T17:33:47.578867Z",
     "shell.execute_reply": "2026-01-23T17:33:47.578177Z"
    },
    "papermill": {
     "duration": 0.011841,
     "end_time": "2026-01-23T17:33:47.580455",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.568614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     'workers': 2,\n",
    "#     'epochs': 10,\n",
    "#     'train_batch_size': 2,\n",
    "#     'val_batch_size': 2,\n",
    "#     'test_batch_size': 2,\n",
    "#     'learning_rate': 1e-3,\n",
    "#     'weight_decay': 1e-5,\n",
    "#     'lambd': 0.0051,\n",
    "#     'data_dir': '/kaggle/input/bratsglioma/Training/',\n",
    "#     'in_checkpoint_dir': Path('/kaggle/input/adultgliomamodel-45epochs'),\n",
    "#     'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "# }\n",
    "\n",
    "# trainLoader, valLoader, testLoader = prepare_data_loaders(args)\n",
    "\n",
    "# for step, y in enumerate( trainLoader ):\n",
    "#   print(y['imgs'].shape)\n",
    "#   print(y['masks'].shape)\n",
    "#   print(y['patient_id'])\n",
    "\n",
    "#   fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "#   for sequence in range(4):\n",
    "#     sequence_data = y['imgs'][0][sequence, :, :, :].cpu().detach().numpy()\n",
    "#     slice_index = sequence_data.shape[2] // 2\n",
    "#     axes[sequence].imshow(sequence_data[:, :, slice_index], cmap='gray', origin='lower')\n",
    "#     axes[sequence].set_title(f'Sequence {sequence + 1}')\n",
    "\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ba50e",
   "metadata": {
    "papermill": {
     "duration": 0.006396,
     "end_time": "2026-01-23T17:33:47.593043",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.586647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DynUNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b4d1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.606823Z",
     "iopub.status.busy": "2026-01-23T17:33:47.606495Z",
     "iopub.status.idle": "2026-01-23T17:33:47.625547Z",
     "shell.execute_reply": "2026-01-23T17:33:47.624911Z"
    },
    "papermill": {
     "duration": 0.027607,
     "end_time": "2026-01-23T17:33:47.626996",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.599389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN module module that can be used for DynUNet, based on:\n",
    "    `Automated Design of Deep Learning Methods for Biomedical Image Segmentation <https://arxiv.org/abs/1904.08128>`_.\n",
    "    `nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation <https://arxiv.org/abs/1809.10486>`_.\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions.\n",
    "        in_channels: number of input channels.\n",
    "        out_channels: number of output channels.\n",
    "        kernel_size: convolution kernel size.\n",
    "        stride: convolution stride.\n",
    "        norm_name: feature normalization type and arguments.\n",
    "        act_name: activation layer type and arguments.\n",
    "        dropout: dropout probability.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[Sequence[int], int],\n",
    "        stride: Union[Sequence[int], int],\n",
    "        norm_name: Union[Tuple, str] = (\"INSTANCE\", {\"affine\": True}),\n",
    "        act_name: Union[Tuple, str] = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            dropout=dropout,\n",
    "            conv_only=True,\n",
    "        )\n",
    "\n",
    "        self.conv2 = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            dropout=dropout,\n",
    "            conv_only=True\n",
    "        )\n",
    "        self.lrelu = get_act_layer(name=act_name)\n",
    "        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n",
    "        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.conv1(inp)\n",
    "        out = self.norm1(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.lrelu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UnetUpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    An upsampling module that can be used for DynUNet, based on:\n",
    "    `Automated Design of Deep Learning Methods for Biomedical Image Segmentation <https://arxiv.org/abs/1904.08128>`_.\n",
    "    `nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation <https://arxiv.org/abs/1809.10486>`_.\n",
    "\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions.\n",
    "        in_channels: number of input channels.\n",
    "        out_channels: number of output channels.\n",
    "        kernel_size: convolution kernel size.\n",
    "        stride: convolution stride.\n",
    "        upsample_kernel_size: convolution kernel size for transposed convolution layers.\n",
    "        norm_name: feature normalization type and arguments.\n",
    "        act_name: activation layer type and arguments.\n",
    "        dropout: dropout probability.\n",
    "        trans_bias: transposed convolution bias.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[Sequence[int], int],\n",
    "        upsample_kernel_size: Union[Sequence[int], int],\n",
    "        norm_name: Union[Tuple, str] = (\"INSTANCE\", {\"affine\": True}),\n",
    "        act_name: Union[Tuple, str] = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n",
    "        dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "        trans_bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        upsample_stride = upsample_kernel_size\n",
    "        \n",
    "        # ( a purple arrow in the paper )\n",
    "        self.transp_conv = get_conv_layer(\n",
    "            spatial_dims,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=upsample_kernel_size,\n",
    "            stride=upsample_stride,\n",
    "            dropout=dropout,\n",
    "            bias=trans_bias,\n",
    "            conv_only=True,\n",
    "            is_transposed=True,\n",
    "        )\n",
    "        \n",
    "        # A light blue conv blocks in the decoder of nnUNet\n",
    "        self.conv_block = UnetBasicBlock(\n",
    "            spatial_dims,\n",
    "            out_channels + out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            dropout=dropout,\n",
    "            norm_name=norm_name,\n",
    "            act_name=act_name,\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, skip):\n",
    "        # number of channels for skip should equals to out_channels\n",
    "        out = self.transp_conv(inp)\n",
    "        out = torch.cat((out, skip), dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UnetOutBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, spatial_dims: int, in_channels: int, out_channels: int, dropout: Optional[Union[Tuple, str, float]] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv = get_conv_layer(\n",
    "            spatial_dims, in_channels, out_channels, kernel_size=1, stride=1, dropout=dropout, bias=True, conv_only=True\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.conv(inp)\n",
    "    \n",
    "\n",
    "def get_conv_layer(\n",
    "    spatial_dims: int,\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: Union[Sequence[int], int] = 3,\n",
    "    stride: Union[Sequence[int], int] = 1,\n",
    "    act: Optional[Union[Tuple, str]] = Act.PRELU,\n",
    "    norm: Union[Tuple, str] = Norm.INSTANCE,\n",
    "    dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "    bias: bool = False,\n",
    "    conv_only: bool = True,\n",
    "    is_transposed: bool = False,\n",
    "):\n",
    "    padding = get_padding(kernel_size, stride)\n",
    "    output_padding = None\n",
    "    if is_transposed:\n",
    "        output_padding = get_output_padding(kernel_size, stride, padding)\n",
    "    \n",
    "    return Convolution(\n",
    "        spatial_dims,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        strides=stride,\n",
    "        kernel_size=kernel_size,\n",
    "        act=act,\n",
    "        norm=norm,\n",
    "        dropout=dropout,\n",
    "        bias=bias,\n",
    "        conv_only=conv_only,\n",
    "        is_transposed=is_transposed,\n",
    "        padding=padding,\n",
    "        output_padding=output_padding,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_padding(\n",
    "    kernel_size: Union[Sequence[int], int], stride: Union[Sequence[int], int]\n",
    ") -> Union[Tuple[int, ...], int]:\n",
    "\n",
    "    kernel_size_np = np.atleast_1d(kernel_size)\n",
    "    stride_np = np.atleast_1d(stride)\n",
    "    padding_np = (kernel_size_np - stride_np + 1) / 2\n",
    "    if np.min(padding_np) < 0:\n",
    "        raise AssertionError(\"padding value should not be negative, please change the kernel size and/or stride.\")\n",
    "    padding = tuple(int(p) for p in padding_np)\n",
    "\n",
    "    return padding if len(padding) > 1 else padding[0]\n",
    "\n",
    "\n",
    "def get_output_padding(\n",
    "    kernel_size: Union[Sequence[int], int], stride: Union[Sequence[int], int], padding: Union[Sequence[int], int]\n",
    ") -> Union[Tuple[int, ...], int]:\n",
    "    kernel_size_np = np.atleast_1d(kernel_size)\n",
    "    stride_np = np.atleast_1d(stride)\n",
    "    padding_np = np.atleast_1d(padding)\n",
    "\n",
    "    out_padding_np = 2 * padding_np + stride_np - kernel_size_np\n",
    "    if np.min(out_padding_np) < 0:\n",
    "        raise AssertionError(\"out_padding value should not be negative, please change the kernel size and/or stride.\")\n",
    "    out_padding = tuple(int(p) for p in out_padding_np)\n",
    "\n",
    "    return out_padding if len(out_padding) > 1 else out_padding[0]\n",
    "\n",
    "def set_requires_grad(nets, requires_grad=False):\n",
    "    if not isinstance(nets, list):\n",
    "        nets = [nets]\n",
    "    for net in nets:\n",
    "        if net is not None:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6151ea3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.640501Z",
     "iopub.status.busy": "2026-01-23T17:33:47.639786Z",
     "iopub.status.idle": "2026-01-23T17:33:47.650137Z",
     "shell.execute_reply": "2026-01-23T17:33:47.649373Z"
    },
    "papermill": {
     "duration": 0.018634,
     "end_time": "2026-01-23T17:33:47.651701",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.633067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. QUANTUM CONFIGURATION ---\n",
    "n_qubits = 10\n",
    "n_layers = 6 # Kept small for training speed; increase to 10 if you have time\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super().__init__()\n",
    "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
    "        self.q_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.q_layer(x)\n",
    "\n",
    "# --- 2. PARALLEL QUANTUM BOTTLENECK ---\n",
    "class ParallelQuantumBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, target_spatial_shape):\n",
    "        super().__init__()\n",
    "        self.target_spatial_shape = target_spatial_shape\n",
    "        self.flat_out_dim = out_channels * np.prod(target_spatial_shape)\n",
    "        \n",
    "        # 1. Classical Down-Projection (Squeeze)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 1, 1)) # Forces size to (Batch, Ch, 1, 1, 1)\n",
    "        self.fc_down = nn.Linear(in_channels, n_qubits)\n",
    "        \n",
    "        # 2. Parallel Quantum Layers (As requested)\n",
    "        self.q_layer1 = QuantumLayer(n_qubits, n_layers)\n",
    "        self.q_layer2 = QuantumLayer(n_qubits, n_layers)\n",
    "        \n",
    "        # 3. Up-Projection\n",
    "        # Input: n_qubits * 2 (concatenated outputs)\n",
    "        self.fc_up = nn.Linear(n_qubits * 2, self.flat_out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "        \n",
    "        # Flatten: (Batch, 384, D, H, W) -> (Batch, 384)\n",
    "        x_flat = self.pool(x).view(b, -1)\n",
    "        \n",
    "        # Squeeze to Quantum Dim: (Batch, 10)\n",
    "        # Using Sigmoid * PI for AngleEmbedding\n",
    "        q_in = torch.sigmoid(self.fc_down(x_flat)) * np.pi\n",
    "        \n",
    "        # Run Parallel Blocks\n",
    "        q_out1 = self.q_layer1(q_in)\n",
    "        q_out2 = self.q_layer2(q_in)\n",
    "        \n",
    "        # Concatenate: (Batch, 20)\n",
    "        q_combined = torch.cat([q_out1, q_out2], dim=1)\n",
    "        \n",
    "        # Up-Project and Reshape\n",
    "        # Returns (Batch, 512, D, H, W)\n",
    "        x_out = self.fc_up(q_combined)\n",
    "        x_out = x_out.view(b, -1, *self.target_spatial_shape)\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426fa084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.665083Z",
     "iopub.status.busy": "2026-01-23T17:33:47.664839Z",
     "iopub.status.idle": "2026-01-23T17:33:47.677847Z",
     "shell.execute_reply": "2026-01-23T17:33:47.677068Z"
    },
    "papermill": {
     "duration": 0.021506,
     "end_time": "2026-01-23T17:33:47.679400",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.657894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DynUNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        deep_supervision: bool,\n",
    "        KD: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.spatial_dims = spatial_dims\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.deep_supervision = deep_supervision\n",
    "        self.KD_enabled = KD\n",
    "        \n",
    "        self.input_conv = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=self.in_channels,\n",
    "                                     out_channels=64,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1\n",
    "                                     )\n",
    "        self.down1 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=64,\n",
    "                                     out_channels=96,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2 # Reduces spatial dims by 2\n",
    "                                     )\n",
    "        self.down2 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=96,\n",
    "                                     out_channels=128,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down3 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=128,\n",
    "                                     out_channels=192,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down4 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=192,\n",
    "                                     out_channels=256,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.down5 = UnetBasicBlock( spatial_dims=self.spatial_dims,\n",
    "                                     in_channels=256,\n",
    "                                     out_channels=384,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=2\n",
    "                                     )\n",
    "        self.quantum_bottleneck = ParallelQuantumBottleneck(\n",
    "                                     in_channels=384,\n",
    "                                     out_channels=512,\n",
    "                                     target_spatial_shape=(2, 2, 2)\n",
    "                                     )\n",
    "        self.up1 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=512,\n",
    "                                out_channels=384,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up2 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=384,\n",
    "                                out_channels=256,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up3 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=256,\n",
    "                                out_channels=192,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.up4 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=192,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        \n",
    "        self.up5 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=128,\n",
    "                                out_channels=96,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )        \n",
    "        self.up6 = UnetUpBlock( spatial_dims=self.spatial_dims,\n",
    "                                in_channels=96,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=3,\n",
    "                                upsample_kernel_size=2\n",
    "                                )\n",
    "        self.out1 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=64,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        self.out2 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=96,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        self.out3 = UnetOutBlock( spatial_dims=self.spatial_dims,\n",
    "                                  in_channels=128,\n",
    "                                  out_channels=self.out_channels,\n",
    "                                  )\n",
    "        \n",
    "    def forward( self, input ):\n",
    "        \n",
    "        # Input\n",
    "        x0 = self.input_conv( input ) # x0.shape = (B x 64 x 128 x 128 x 128)\n",
    "        \n",
    "        # Encoder\n",
    "        x1 = self.down1( x0 ) # x1.shape = (B x 96 x 64 x 64 x 64) \n",
    "        x2 = self.down2( x1 ) # x2.shape = (B x 128 x 32 x 32 x 32)\n",
    "        x3 = self.down3( x2 ) # x3.shape = (B x 192 x 16 x 16 x 16)\n",
    "        x4 = self.down4( x3 ) # x4.shape = (B x 256 x 8 x 8 x 8)   \n",
    "        x5 = self.down5( x4 ) # x5.shape = (B x 384 x 4 x 4 x 4)   \n",
    "        \n",
    "        # Bottleneck\n",
    "        x6 = self.quantum_bottleneck( x5 ) # x6.shape = (B x 512 x 2 x 2 x 2)\n",
    "        \n",
    "        # Decoder\n",
    "        x7  = self.up1( x6, x5 )  # x7.shape  = (B x 384 x 4 x 4 x 4)\n",
    "        x8  = self.up2( x7, x4 )  # x8.shape  = (B x 256 x 8 x 8 x 8)\n",
    "        x9  = self.up3( x8, x3 )  # x9.shape  = (B x 192 x 16 x 16 x 16)\n",
    "        x10 = self.up4( x9, x2 )  # x10.shape = (B x 128 x 32 x 32 x 32)\n",
    "        x11 = self.up5( x10, x1 ) # x11.shape = (B x 96 x 64 x 64 x 64)\n",
    "        x12 = self.up6( x11, x0 ) # x12.shape = (B x 64 x 128 x 128 x 128)\n",
    "        \n",
    "        # Output\n",
    "        output1 = self.out1( x12 )\n",
    "        \n",
    "        if (self.training and self.deep_supervision) or self.KD_enabled:\n",
    "            \n",
    "            # output['pred'].shape = B x 3 x 4 x 128 x 128 x 128\n",
    "            output2 = interpolate( self.out2( x11 ), output1.shape[2:])\n",
    "            output3 = interpolate( self.out3( x10 ), output1.shape[2:])\n",
    "            output_all = [ output1, output2, output3 ]\n",
    "            return { 'pred' : torch.stack(output_all, dim=1),\n",
    "                     'bottleneck_feature_map' : x6 }\n",
    "        \n",
    "        return { 'pred' : output1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa063ef7",
   "metadata": {
    "papermill": {
     "duration": 0.006006,
     "end_time": "2026-01-23T17:33:47.691608",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.685602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualizing Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a883baae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.704763Z",
     "iopub.status.busy": "2026-01-23T17:33:47.704483Z",
     "iopub.status.idle": "2026-01-23T17:33:47.707796Z",
     "shell.execute_reply": "2026-01-23T17:33:47.707067Z"
    },
    "papermill": {
     "duration": 0.011511,
     "end_time": "2026-01-23T17:33:47.709199",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.697688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "# from torchsummary import summary\n",
    "\n",
    "# # Initialize your DynUNet model\n",
    "# model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=True, KD=True)\n",
    "\n",
    "# # Print model summary\n",
    "# summary(model, input_size=(4, 128, 128, 128))  # Adjust input_size according to your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06842592",
   "metadata": {
    "papermill": {
     "duration": 0.005929,
     "end_time": "2026-01-23T17:33:47.721336",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.715407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebe3550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:33:47.734387Z",
     "iopub.status.busy": "2026-01-23T17:33:47.734141Z",
     "iopub.status.idle": "2026-01-23T17:34:00.688836Z",
     "shell.execute_reply": "2026-01-23T17:34:00.687745Z"
    },
    "papermill": {
     "duration": 12.963349,
     "end_time": "2026-01-23T17:34:00.690731",
     "exception": false,
     "start_time": "2026-01-23T17:33:47.727382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clearml\r\n",
      "  Downloading clearml-2.1.2-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: attrs>=18.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (23.2.0)\r\n",
      "Collecting furl>=2.0.0 (from clearml)\r\n",
      "  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (4.22.0)\r\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.4)\r\n",
      "Collecting pathlib2>=2.3.0 (from clearml)\r\n",
      "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: psutil>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from clearml) (5.9.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from clearml) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.8.0)\r\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.10/site-packages (from clearml) (6.0.2)\r\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.18)\r\n",
      "Requirement already satisfied: Pillow>=10.3.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (10.3.0)\r\n",
      "Requirement already satisfied: referencing<0.40 in /opt/conda/lib/python3.10/site-packages (from clearml) (0.35.1)\r\n",
      "Requirement already satisfied: requests>=2.32.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.32.3)\r\n",
      "Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\r\n",
      "  Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (0.18.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.0->clearml) (2024.8.30)\r\n",
      "Downloading clearml-2.1.2-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\r\n",
      "Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading orderedmultidict-1.0.2-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: pathlib2, orderedmultidict, furl, clearml\r\n",
      "Successfully installed clearml-2.1.2 furl-2.1.4 orderedmultidict-1.0.2 pathlib2-2.3.7.post1\r\n",
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=OT8WDYYRPS77UQDYEF00V77QHBX4I7\n",
      "env: CLEARML_API_SECRET_KEY=5u-2jo49-W9f5ycmIG9WOIjYbquANMlxfCDEpSnZ7Bokb_E3txLvxgSXwwf4r54O4W0\n"
     ]
    }
   ],
   "source": [
    "!pip install clearml\n",
    "from clearml import Task\n",
    "\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=OT8WDYYRPS77UQDYEF00V77QHBX4I7\n",
    "%env CLEARML_API_SECRET_KEY=5u-2jo49-W9f5ycmIG9WOIjYbquANMlxfCDEpSnZ7Bokb_E3txLvxgSXwwf4r54O4W0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42717e55",
   "metadata": {
    "papermill": {
     "duration": 0.006887,
     "end_time": "2026-01-23T17:34:00.704889",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.698002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76fdbbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:34:00.720848Z",
     "iopub.status.busy": "2026-01-23T17:34:00.719671Z",
     "iopub.status.idle": "2026-01-23T17:34:00.726527Z",
     "shell.execute_reply": "2026-01-23T17:34:00.725719Z"
    },
    "papermill": {
     "duration": 0.016204,
     "end_time": "2026-01-23T17:34:00.728039",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.711835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.dice = DiceLoss(sigmoid=True, batch=True, smooth_nr=1e-05, smooth_dr=1e-05)\n",
    "        self.ce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def _loss(self, p, y):\n",
    "        return self.dice(p, y) + self.ce(p, y.float())\n",
    "\n",
    "    def forward(self, p, y):\n",
    "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
    "        p_wt, p_tc, p_et = p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1), p[:, 3].unsqueeze(1)\n",
    "        l_wt, l_tc, l_et = self._loss(p_wt, y_wt), self._loss(p_tc, y_tc), self._loss(p_et, y_et)\n",
    "        return l_wt + l_tc + l_et"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777c656",
   "metadata": {
    "papermill": {
     "duration": 0.006767,
     "end_time": "2026-01-23T17:34:00.741604",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.734837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3111aa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:34:00.756356Z",
     "iopub.status.busy": "2026-01-23T17:34:00.756100Z",
     "iopub.status.idle": "2026-01-23T17:34:00.762161Z",
     "shell.execute_reply": "2026-01-23T17:34:00.761337Z"
    },
    "papermill": {
     "duration": 0.015282,
     "end_time": "2026-01-23T17:34:00.763759",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.748477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, epoch): # teacher_model, valLoader, epoch\n",
    "    torch.manual_seed(0)\n",
    "    model.eval()\n",
    "    \n",
    "    loss_fn = LossFunction()\n",
    "    n_val_batches = len(loader)\n",
    "    running_loss = 0\n",
    "\n",
    "    with tqdm(total=n_val_batches, desc='Validating', unit='batch', leave=False) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for step, y in enumerate(loader):\n",
    "                y['imgs'], y['masks']= y['imgs'].to('cuda'), y['masks'].to('cuda')\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    output = model(y['imgs']) # No need now for KD!\n",
    "                    val_loss = loss_fn( output['pred'], y['masks'] ) #output['pred'] has 'pred' only due to model.eval() so self.training = False\n",
    "                    print(f\"Validation loss per batch: {val_loss}\")\n",
    "                    \n",
    "                running_loss += val_loss\n",
    "                print(f\"Cumulative loss: {running_loss}\")            \n",
    "                pbar.update(1)\n",
    "    \n",
    "            epoch_loss = running_loss / n_val_batches\n",
    "            print(f\"------Final validation loss after epoch {epoch + 1}: {epoch_loss}-------------\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce40f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:34:00.778932Z",
     "iopub.status.busy": "2026-01-23T17:34:00.778706Z",
     "iopub.status.idle": "2026-01-23T17:34:00.793413Z",
     "shell.execute_reply": "2026-01-23T17:34:00.792762Z"
    },
    "papermill": {
     "duration": 0.024164,
     "end_time": "2026-01-23T17:34:00.794909",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.770745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(trainLoader, valLoader, args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    args['out_checkpoint_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    task = Task.init(project_name=\"PediatricModelSegmentation\", task_name=f\"Finalized Pediatric Segmentation _ Epochs AdamW\", reuse_last_task_id=True)\n",
    "    task.connect(args)\n",
    "\n",
    "    loss_fn = LossFunction()\n",
    "    teacher_model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=True).to(device)\n",
    "    optimizer_teacher = optim.AdamW(teacher_model.parameters(), lr=args['learning_rate'], weight_decay=args['weight_decay'], eps=1e-4)\n",
    "    # optimizer_teacher = optim.SGD(teacher_model.parameters(), lr=args['learning_rate'], weight_decay=args['weight_decay'],\n",
    "    #                                     momentum=0.99, nesterov=True)\n",
    "    scaler = amp.GradScaler()\n",
    "    n_train_batches = len(trainLoader)\n",
    "    scheduler_teacher = optim.lr_scheduler.ReduceLROnPlateau(optimizer_teacher, mode='min', factor=0.1, patience=6, cooldown=1, threshold=0.001, min_lr=1e-6)\n",
    "    # scheduler_teacher = PolyLRScheduler(optimizer_teacher, initial_lr=args['learning_rate'], max_steps=120)\n",
    "\n",
    "    teacher_epoch_checkpoint = f'Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth'\n",
    "    if (args['in_checkpoint_dir'] / teacher_epoch_checkpoint).is_file():\n",
    "        print(f\"Found model {teacher_epoch_checkpoint}\")\n",
    "        ckpt = torch.load(args['in_checkpoint_dir'] / teacher_epoch_checkpoint, map_location='cuda', weights_only=True)\n",
    "        start_epoch = ckpt['epoch'] + 1 # To start after last saved epoch\n",
    "        teacher_model.load_state_dict(ckpt['teacher_model'])\n",
    "        optimizer_teacher.load_state_dict(ckpt['optimizer_teacher'])\n",
    "        scaler.load_state_dict(ckpt['grad_scaler_state'])\n",
    "        scheduler_teacher.load_state_dict(ckpt['scheduler_state_dict'])\n",
    "        # optimizer_teacher.param_groups[0]['lr'] = args['learning_rate'] # Leave this (overwrite) or remove it as you wish\n",
    "        print(f\"Loaded model {teacher_epoch_checkpoint} with lr: {optimizer_teacher.param_groups[0]['lr']}\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    print(f'''Starting training:\n",
    "            Epochs:          From {start_epoch + 1} to {start_epoch + args['epochs']}\n",
    "            Batch size:      {args['train_batch_size']}\n",
    "            Learning rate:   {optimizer_teacher.param_groups[0]['lr']}\n",
    "            Training data coming from:   {args['data_dir']}\n",
    "    ''')\n",
    "\n",
    "    # Starting training\n",
    "    for epoch in range(start_epoch, start_epoch + args['epochs']):\n",
    "        teacher_model.train()\n",
    "        epoch_loss_teacher = 0\n",
    "        \n",
    "        with tqdm(total=n_train_batches, desc=f\"(Epoch {epoch + 1}/{start_epoch + args['epochs']})\", unit='batch') as pbar:\n",
    "            for step, y in enumerate(trainLoader):\n",
    "                y['imgs'], y['masks']= y['imgs'].to(device), y['masks'].to(device)\n",
    "\n",
    "                set_requires_grad(teacher_model, requires_grad=True)\n",
    "                optimizer_teacher.zero_grad()\n",
    "                with amp.autocast():  # Mixed precision\n",
    "                    teacher_output = teacher_model(y['imgs'])\n",
    "                    loss_teacher_decoder_1 = loss_fn(teacher_output['pred'][:, 0], y['masks']) # B x 3 x 4 x 128 x 128 x 128\n",
    "                    loss_teacher_decoder_2 = loss_fn(teacher_output['pred'][:, 1], y['masks'])\n",
    "                    loss_teacher_decoder_3 = loss_fn(teacher_output['pred'][:, 2], y['masks'])\n",
    "\n",
    "                    print(f'loss_t_decoder1/batch : {loss_teacher_decoder_1:.4f} || loss_t_decoder2/batch : {loss_teacher_decoder_2:.4f} || loss_t_decoder3/batch : {loss_teacher_decoder_3:.4f}')\n",
    "                    batch_loss_teacher = loss_teacher_decoder_1 + (0.5 * loss_teacher_decoder_2) + (0.25 * loss_teacher_decoder_3)\n",
    "\n",
    "                scaler.scale(batch_loss_teacher).backward()\n",
    "                scaler.step(optimizer_teacher)\n",
    "                scaler.update()\n",
    "\n",
    "                epoch_loss_teacher += batch_loss_teacher.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "            epoch_loss_teacher /= n_train_batches\n",
    "            print(f\"------Final training loss after epoch {epoch + 1}: {epoch_loss_teacher}-------------\")\n",
    "\n",
    "            task.get_logger().report_scalar(\"Loss\", \"train_loss\", iteration=epoch+1, value=epoch_loss_teacher)\n",
    "            task.get_logger().report_scalar(\"LR\", \"learning_rate\", iteration=epoch+1, value=optimizer_teacher.param_groups[0]['lr'])\n",
    "\n",
    "        # Validation phase\n",
    "        print(f'''\n",
    "            Starting validation:\n",
    "            Epoch:           {epoch + 1}\n",
    "            Batch size:      {args['val_batch_size']}\n",
    "            Validation data coming from: {args['data_dir']}\n",
    "\n",
    "        ''')\n",
    "\n",
    "        val_loss = evaluate(teacher_model, valLoader, epoch)\n",
    "        scheduler_teacher.step(val_loss)\n",
    "        print(f\"Learning rate after epoch {epoch + 1}: {optimizer_teacher.param_groups[0]['lr']}\")\n",
    "        task.get_logger().report_scalar(\"Loss\", \"val_loss\", iteration=epoch+1, value=val_loss)\n",
    "\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'teacher_model': teacher_model.state_dict(),\n",
    "            'optimizer_teacher': optimizer_teacher.state_dict(),\n",
    "            'lr': optimizer_teacher.param_groups[0]['lr'],\n",
    "            'grad_scaler_state': scaler.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler_teacher.state_dict(),\n",
    "            'val_loss': val_loss\n",
    "\n",
    "        }\n",
    "\n",
    "        torch.save(state, args['out_checkpoint_dir'] / f'Teacher_model_after_epoch_{epoch + 1}_trainLoss_{epoch_loss_teacher:.4f}_valLoss_{val_loss:.4f}.pth')\n",
    "        print(f\"Model saved after epoch {epoch + 1}\")\n",
    "        # task.upload_artifact(name=f\"model_checkpoint_epoch_{epoch + 1}\", artifact_object=checkpoint_path)\n",
    "\n",
    "    task.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b36264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:34:00.810049Z",
     "iopub.status.busy": "2026-01-23T17:34:00.809792Z",
     "iopub.status.idle": "2026-01-23T18:34:40.985386Z",
     "shell.execute_reply": "2026-01-23T18:34:40.984155Z"
    },
    "papermill": {
     "duration": 3640.187738,
     "end_time": "2026-01-23T18:34:40.989625",
     "exception": false,
     "start_time": "2026-01-23T17:34:00.801887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 69\n",
      "Number of validation samples 9\n",
      "Number of testing samples 21\n",
      "Using device: cuda\n",
      "ClearML Task: created new task id=ee8084326a7843b5b479e41e49f10868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed accessing the jupyter server(s): []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: https://app.clear.ml/projects/5b1fade283884232bed7d2c9d7e34fca/experiments/ee8084326a7843b5b479e41e49f10868/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameters must be of builtin type (General/in_checkpoint_dir[PosixPath], General/out_checkpoint_dir[PosixPath])\n",
      "/tmp/ipykernel_24/19370901.py:16: FutureWarning:\n",
      "\n",
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth\n",
      "Loaded model Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth with lr: 0.001\n",
      "Starting training:\n",
      "            Epochs:          From 26 to 50\n",
      "            Batch size:      2\n",
      "            Learning rate:   0.001\n",
      "            Training data coming from:   /kaggle/input/bratsped/Training\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/tmp/ipykernel_24/19370901.py:53: FutureWarning:\n",
      "\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/pennylane/ops/qubit/parametric_ops_single_qubit.py:131: UserWarning:\n",
      "\n",
      "ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/EmptyTensor.cpp:44.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6069 || loss_t_decoder2/batch : 1.7143 || loss_t_decoder3/batch : 1.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):   3%|▎         | 1/35 [00:12<07:01, 12.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6071 || loss_t_decoder2/batch : 0.6515 || loss_t_decoder3/batch : 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):   6%|▌         | 2/35 [00:16<04:03,  7.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0248 || loss_t_decoder2/batch : 1.0883 || loss_t_decoder3/batch : 1.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):   9%|▊         | 3/35 [00:20<03:05,  5.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1024 || loss_t_decoder2/batch : 1.1466 || loss_t_decoder3/batch : 1.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  11%|█▏        | 4/35 [00:23<02:35,  5.02s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8136 || loss_t_decoder2/batch : 0.8465 || loss_t_decoder3/batch : 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  14%|█▍        | 5/35 [00:27<02:17,  4.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3936 || loss_t_decoder2/batch : 1.4134 || loss_t_decoder3/batch : 1.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  17%|█▋        | 6/35 [00:31<02:06,  4.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3564 || loss_t_decoder2/batch : 1.3119 || loss_t_decoder3/batch : 1.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  20%|██        | 7/35 [00:35<01:57,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3136 || loss_t_decoder2/batch : 1.3329 || loss_t_decoder3/batch : 1.4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  23%|██▎       | 8/35 [00:39<01:50,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2764 || loss_t_decoder2/batch : 1.2824 || loss_t_decoder3/batch : 1.4407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  26%|██▌       | 9/35 [00:43<01:44,  4.02s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2244 || loss_t_decoder2/batch : 1.3086 || loss_t_decoder3/batch : 1.4790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  29%|██▊       | 10/35 [00:47<01:39,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.8187 || loss_t_decoder2/batch : 1.7294 || loss_t_decoder3/batch : 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  31%|███▏      | 11/35 [00:51<01:34,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7908 || loss_t_decoder2/batch : 0.8081 || loss_t_decoder3/batch : 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  34%|███▍      | 12/35 [00:54<01:30,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8455 || loss_t_decoder2/batch : 0.8918 || loss_t_decoder3/batch : 1.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  37%|███▋      | 13/35 [00:58<01:26,  3.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.7131 || loss_t_decoder2/batch : 1.7426 || loss_t_decoder3/batch : 1.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  40%|████      | 14/35 [01:02<01:21,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2469 || loss_t_decoder2/batch : 1.3067 || loss_t_decoder3/batch : 1.4043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  43%|████▎     | 15/35 [01:06<01:17,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8483 || loss_t_decoder2/batch : 0.8928 || loss_t_decoder3/batch : 1.0553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  46%|████▌     | 16/35 [01:10<01:13,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5313 || loss_t_decoder2/batch : 1.6133 || loss_t_decoder3/batch : 1.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  49%|████▊     | 17/35 [01:14<01:10,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0026 || loss_t_decoder2/batch : 0.9520 || loss_t_decoder3/batch : 0.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  51%|█████▏    | 18/35 [01:18<01:06,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7732 || loss_t_decoder2/batch : 0.9072 || loss_t_decoder3/batch : 1.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  54%|█████▍    | 19/35 [01:22<01:02,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1333 || loss_t_decoder2/batch : 1.1626 || loss_t_decoder3/batch : 1.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  57%|█████▋    | 20/35 [01:25<00:58,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2914 || loss_t_decoder2/batch : 1.3250 || loss_t_decoder3/batch : 1.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  60%|██████    | 21/35 [01:29<00:54,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5533 || loss_t_decoder2/batch : 0.6615 || loss_t_decoder3/batch : 0.9507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  63%|██████▎   | 22/35 [01:33<00:50,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0365 || loss_t_decoder2/batch : 1.1015 || loss_t_decoder3/batch : 1.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  66%|██████▌   | 23/35 [01:37<00:46,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2650 || loss_t_decoder2/batch : 1.3169 || loss_t_decoder3/batch : 1.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  69%|██████▊   | 24/35 [01:41<00:42,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9045 || loss_t_decoder2/batch : 1.9465 || loss_t_decoder3/batch : 1.9479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  71%|███████▏  | 25/35 [01:45<00:38,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0082 || loss_t_decoder2/batch : 1.0252 || loss_t_decoder3/batch : 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  74%|███████▍  | 26/35 [01:49<00:35,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1560 || loss_t_decoder2/batch : 1.1451 || loss_t_decoder3/batch : 1.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  77%|███████▋  | 27/35 [01:53<00:31,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0160 || loss_t_decoder2/batch : 1.0499 || loss_t_decoder3/batch : 1.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  80%|████████  | 28/35 [01:57<00:27,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9890 || loss_t_decoder2/batch : 1.0472 || loss_t_decoder3/batch : 1.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  83%|████████▎ | 29/35 [02:01<00:23,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9088 || loss_t_decoder2/batch : 0.9549 || loss_t_decoder3/batch : 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  86%|████████▌ | 30/35 [02:04<00:19,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8871 || loss_t_decoder2/batch : 0.9462 || loss_t_decoder3/batch : 1.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  89%|████████▊ | 31/35 [02:08<00:15,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0972 || loss_t_decoder2/batch : 1.1473 || loss_t_decoder3/batch : 1.3041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  91%|█████████▏| 32/35 [02:12<00:11,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3959 || loss_t_decoder2/batch : 1.4275 || loss_t_decoder3/batch : 1.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  94%|█████████▍| 33/35 [02:16<00:07,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1821 || loss_t_decoder2/batch : 1.2031 || loss_t_decoder3/batch : 1.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50):  97%|█████████▋| 34/35 [02:20<00:03,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2317 || loss_t_decoder2/batch : 1.3699 || loss_t_decoder3/batch : 1.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 26/50): 100%|██████████| 35/35 [02:22<00:00,  4.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 26: 2.071066669055394-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           26\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:05<00:23,  5.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.270896315574646\n",
      "Cumulative loss: 1.270896315574646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:07<00:09,  3.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2401413917541504\n",
      "Cumulative loss: 2.511037826538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:10<00:06,  3.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.135654091835022\n",
      "Cumulative loss: 3.6466917991638184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:11<00:02,  2.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8394078016281128\n",
      "Cumulative loss: 4.486099720001221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1012860536575317\n",
      "Cumulative loss: 5.587385654449463\n",
      "------Final validation loss after epoch 26: 1.1174771785736084-------------\n",
      "Learning rate after epoch 26: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1677 || loss_t_decoder2/batch : 1.1706 || loss_t_decoder3/batch : 1.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):   3%|▎         | 1/35 [00:05<03:17,  5.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5306 || loss_t_decoder2/batch : 1.5556 || loss_t_decoder3/batch : 1.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):   6%|▌         | 2/35 [00:09<02:32,  4.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9331 || loss_t_decoder2/batch : 0.9513 || loss_t_decoder3/batch : 1.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):   9%|▊         | 3/35 [00:13<02:15,  4.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3522 || loss_t_decoder2/batch : 1.4733 || loss_t_decoder3/batch : 1.5334\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  11%|█▏        | 4/35 [00:17<02:05,  4.06s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3156 || loss_t_decoder2/batch : 1.3644 || loss_t_decoder3/batch : 1.4556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  14%|█▍        | 5/35 [00:20<01:58,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1888 || loss_t_decoder2/batch : 1.2558 || loss_t_decoder3/batch : 1.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  17%|█▋        | 6/35 [00:24<01:53,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6894 || loss_t_decoder2/batch : 0.7339 || loss_t_decoder3/batch : 0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  20%|██        | 7/35 [00:28<01:48,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8317 || loss_t_decoder2/batch : 0.8230 || loss_t_decoder3/batch : 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  23%|██▎       | 8/35 [00:32<01:44,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0645 || loss_t_decoder2/batch : 1.0760 || loss_t_decoder3/batch : 1.0820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2230 || loss_t_decoder2/batch : 1.2303 || loss_t_decoder3/batch : 1.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  29%|██▊       | 10/35 [00:39<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2652 || loss_t_decoder2/batch : 1.2957 || loss_t_decoder3/batch : 1.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9612 || loss_t_decoder2/batch : 0.9916 || loss_t_decoder3/batch : 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  34%|███▍      | 12/35 [00:47<01:27,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 2.0167 || loss_t_decoder2/batch : 1.9461 || loss_t_decoder3/batch : 2.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  37%|███▋      | 13/35 [00:51<01:23,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6639 || loss_t_decoder2/batch : 0.7401 || loss_t_decoder3/batch : 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1742 || loss_t_decoder2/batch : 1.4458 || loss_t_decoder3/batch : 1.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  43%|████▎     | 15/35 [00:58<01:16,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9774 || loss_t_decoder2/batch : 0.9898 || loss_t_decoder3/batch : 1.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2317 || loss_t_decoder2/batch : 1.1734 || loss_t_decoder3/batch : 1.3096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4246 || loss_t_decoder2/batch : 1.3905 || loss_t_decoder3/batch : 1.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1111 || loss_t_decoder2/batch : 1.1385 || loss_t_decoder3/batch : 1.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6826 || loss_t_decoder2/batch : 1.6589 || loss_t_decoder3/batch : 1.6203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  57%|█████▋    | 20/35 [01:18<00:59,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8782 || loss_t_decoder2/batch : 0.9585 || loss_t_decoder3/batch : 1.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  60%|██████    | 21/35 [01:22<00:55,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9010 || loss_t_decoder2/batch : 0.9408 || loss_t_decoder3/batch : 1.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  63%|██████▎   | 22/35 [01:26<00:50,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6734 || loss_t_decoder2/batch : 1.6625 || loss_t_decoder3/batch : 1.7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  66%|██████▌   | 23/35 [01:29<00:46,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2783 || loss_t_decoder2/batch : 1.2565 || loss_t_decoder3/batch : 1.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  69%|██████▊   | 24/35 [01:33<00:42,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0871 || loss_t_decoder2/batch : 1.1149 || loss_t_decoder3/batch : 1.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  71%|███████▏  | 25/35 [01:37<00:38,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9722 || loss_t_decoder2/batch : 0.9983 || loss_t_decoder3/batch : 1.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9722 || loss_t_decoder2/batch : 0.9715 || loss_t_decoder3/batch : 1.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  77%|███████▋  | 27/35 [01:45<00:30,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 2.0835 || loss_t_decoder2/batch : 1.9813 || loss_t_decoder3/batch : 2.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  80%|████████  | 28/35 [01:48<00:26,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3154 || loss_t_decoder2/batch : 1.3654 || loss_t_decoder3/batch : 1.4945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9997 || loss_t_decoder2/batch : 1.0226 || loss_t_decoder3/batch : 1.1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7157 || loss_t_decoder2/batch : 0.7754 || loss_t_decoder3/batch : 1.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  89%|████████▊ | 31/35 [02:00<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9902 || loss_t_decoder2/batch : 1.0837 || loss_t_decoder3/batch : 1.2742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  91%|█████████▏| 32/35 [02:04<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1414 || loss_t_decoder2/batch : 1.1806 || loss_t_decoder3/batch : 1.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4581 || loss_t_decoder2/batch : 1.4989 || loss_t_decoder3/batch : 1.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7565 || loss_t_decoder2/batch : 0.7730 || loss_t_decoder3/batch : 0.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 27/50): 100%|██████████| 35/35 [02:14<00:00,  3.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 27: 2.096054124832153-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           27\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0200622081756592\n",
      "Cumulative loss: 1.0200622081756592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2556078433990479\n",
      "Cumulative loss: 2.275670051574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1533608436584473\n",
      "Cumulative loss: 3.4290308952331543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9575061798095703\n",
      "Cumulative loss: 4.386537075042725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1270381212234497\n",
      "Cumulative loss: 5.513575077056885\n",
      "------Final validation loss after epoch 27: 1.102715015411377-------------\n",
      "Learning rate after epoch 27: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2171 || loss_t_decoder2/batch : 1.2110 || loss_t_decoder3/batch : 1.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):   3%|▎         | 1/35 [00:05<03:21,  5.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6190 || loss_t_decoder2/batch : 1.6317 || loss_t_decoder3/batch : 1.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):   6%|▌         | 2/35 [00:09<02:33,  4.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8679 || loss_t_decoder2/batch : 0.9042 || loss_t_decoder3/batch : 1.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):   9%|▊         | 3/35 [00:13<02:16,  4.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.7102 || loss_t_decoder2/batch : 1.7051 || loss_t_decoder3/batch : 1.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  11%|█▏        | 4/35 [00:17<02:06,  4.09s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2337 || loss_t_decoder2/batch : 1.2834 || loss_t_decoder3/batch : 1.3867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  14%|█▍        | 5/35 [00:21<01:59,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4647 || loss_t_decoder2/batch : 1.5442 || loss_t_decoder3/batch : 1.5114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  17%|█▋        | 6/35 [00:24<01:53,  3.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7076 || loss_t_decoder2/batch : 0.6847 || loss_t_decoder3/batch : 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  20%|██        | 7/35 [00:28<01:48,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8055 || loss_t_decoder2/batch : 0.7832 || loss_t_decoder3/batch : 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  23%|██▎       | 8/35 [00:32<01:43,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0908 || loss_t_decoder2/batch : 1.1697 || loss_t_decoder3/batch : 1.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2942 || loss_t_decoder2/batch : 1.3814 || loss_t_decoder3/batch : 1.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2752 || loss_t_decoder2/batch : 1.3158 || loss_t_decoder3/batch : 1.4373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  31%|███▏      | 11/35 [00:43<01:31,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0962 || loss_t_decoder2/batch : 1.0533 || loss_t_decoder3/batch : 1.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9439 || loss_t_decoder2/batch : 1.9766 || loss_t_decoder3/batch : 2.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6222 || loss_t_decoder2/batch : 0.6973 || loss_t_decoder3/batch : 0.8694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4836 || loss_t_decoder2/batch : 1.5160 || loss_t_decoder3/batch : 1.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  43%|████▎     | 15/35 [00:59<01:15,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0054 || loss_t_decoder2/batch : 1.0596 || loss_t_decoder3/batch : 1.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1445 || loss_t_decoder2/batch : 1.1562 || loss_t_decoder3/batch : 1.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3042 || loss_t_decoder2/batch : 1.3209 || loss_t_decoder3/batch : 1.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2468 || loss_t_decoder2/batch : 1.3422 || loss_t_decoder3/batch : 1.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.7020 || loss_t_decoder2/batch : 1.8201 || loss_t_decoder3/batch : 1.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8916 || loss_t_decoder2/batch : 0.9738 || loss_t_decoder3/batch : 1.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0245 || loss_t_decoder2/batch : 1.0879 || loss_t_decoder3/batch : 1.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5946 || loss_t_decoder2/batch : 1.4850 || loss_t_decoder3/batch : 1.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1883 || loss_t_decoder2/batch : 1.1380 || loss_t_decoder3/batch : 1.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9570 || loss_t_decoder2/batch : 0.9939 || loss_t_decoder3/batch : 1.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8670 || loss_t_decoder2/batch : 0.9385 || loss_t_decoder3/batch : 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8770 || loss_t_decoder2/batch : 0.9818 || loss_t_decoder3/batch : 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5697 || loss_t_decoder2/batch : 1.7062 || loss_t_decoder3/batch : 1.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3808 || loss_t_decoder2/batch : 1.3950 || loss_t_decoder3/batch : 1.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9727 || loss_t_decoder2/batch : 1.0486 || loss_t_decoder3/batch : 1.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6973 || loss_t_decoder2/batch : 0.7296 || loss_t_decoder3/batch : 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9599 || loss_t_decoder2/batch : 0.9520 || loss_t_decoder3/batch : 1.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9717 || loss_t_decoder2/batch : 0.8094 || loss_t_decoder3/batch : 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3695 || loss_t_decoder2/batch : 1.4248 || loss_t_decoder3/batch : 1.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7692 || loss_t_decoder2/batch : 0.8587 || loss_t_decoder3/batch : 1.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 28/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 28: 2.0975973129272463-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           28\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8206524848937988\n",
      "Cumulative loss: 0.8206524848937988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2395339012145996\n",
      "Cumulative loss: 2.0601863861083984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1509116888046265\n",
      "Cumulative loss: 3.2110981941223145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8893157243728638\n",
      "Cumulative loss: 4.100413799285889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1204113960266113\n",
      "Cumulative loss: 5.2208251953125\n",
      "------Final validation loss after epoch 28: 1.044165015220642-------------\n",
      "Learning rate after epoch 28: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1584 || loss_t_decoder2/batch : 1.1168 || loss_t_decoder3/batch : 1.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):   3%|▎         | 1/35 [00:05<03:18,  5.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5165 || loss_t_decoder2/batch : 1.5588 || loss_t_decoder3/batch : 1.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):   6%|▌         | 2/35 [00:09<02:32,  4.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8502 || loss_t_decoder2/batch : 0.8821 || loss_t_decoder3/batch : 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):   9%|▊         | 3/35 [00:13<02:16,  4.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5825 || loss_t_decoder2/batch : 1.5686 || loss_t_decoder3/batch : 1.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  11%|█▏        | 4/35 [00:17<02:06,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2491 || loss_t_decoder2/batch : 1.2922 || loss_t_decoder3/batch : 1.3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  14%|█▍        | 5/35 [00:21<01:59,  3.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2612 || loss_t_decoder2/batch : 1.3523 || loss_t_decoder3/batch : 1.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  17%|█▋        | 6/35 [00:24<01:53,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6893 || loss_t_decoder2/batch : 0.7404 || loss_t_decoder3/batch : 0.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  20%|██        | 7/35 [00:28<01:48,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7537 || loss_t_decoder2/batch : 0.7588 || loss_t_decoder3/batch : 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  23%|██▎       | 8/35 [00:32<01:44,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0440 || loss_t_decoder2/batch : 1.0604 || loss_t_decoder3/batch : 1.1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1598 || loss_t_decoder2/batch : 1.1535 || loss_t_decoder3/batch : 1.1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  29%|██▊       | 10/35 [00:40<01:35,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2691 || loss_t_decoder2/batch : 1.3179 || loss_t_decoder3/batch : 1.4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  31%|███▏      | 11/35 [00:43<01:31,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0403 || loss_t_decoder2/batch : 1.0032 || loss_t_decoder3/batch : 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9790 || loss_t_decoder2/batch : 1.9608 || loss_t_decoder3/batch : 2.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  37%|███▋      | 13/35 [00:51<01:23,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6401 || loss_t_decoder2/batch : 0.7196 || loss_t_decoder3/batch : 0.8579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  40%|████      | 14/35 [00:55<01:19,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3242 || loss_t_decoder2/batch : 1.2912 || loss_t_decoder3/batch : 1.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9658 || loss_t_decoder2/batch : 1.0436 || loss_t_decoder3/batch : 1.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2419 || loss_t_decoder2/batch : 1.1174 || loss_t_decoder3/batch : 1.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2920 || loss_t_decoder2/batch : 1.1787 || loss_t_decoder3/batch : 1.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0393 || loss_t_decoder2/batch : 1.0590 || loss_t_decoder3/batch : 1.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6093 || loss_t_decoder2/batch : 1.5947 || loss_t_decoder3/batch : 1.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8777 || loss_t_decoder2/batch : 0.9323 || loss_t_decoder3/batch : 1.0949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8492 || loss_t_decoder2/batch : 0.9279 || loss_t_decoder3/batch : 1.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4865 || loss_t_decoder2/batch : 1.5017 || loss_t_decoder3/batch : 1.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2935 || loss_t_decoder2/batch : 1.2862 || loss_t_decoder3/batch : 1.3573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9576 || loss_t_decoder2/batch : 0.9564 || loss_t_decoder3/batch : 1.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8814 || loss_t_decoder2/batch : 0.8431 || loss_t_decoder3/batch : 1.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8916 || loss_t_decoder2/batch : 0.8563 || loss_t_decoder3/batch : 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6231 || loss_t_decoder2/batch : 1.6279 || loss_t_decoder3/batch : 1.6827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3280 || loss_t_decoder2/batch : 1.3210 || loss_t_decoder3/batch : 1.3933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9639 || loss_t_decoder2/batch : 0.9451 || loss_t_decoder3/batch : 1.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6935 || loss_t_decoder2/batch : 0.8158 || loss_t_decoder3/batch : 0.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9219 || loss_t_decoder2/batch : 0.9782 || loss_t_decoder3/batch : 1.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9190 || loss_t_decoder2/batch : 1.0103 || loss_t_decoder3/batch : 1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4598 || loss_t_decoder2/batch : 1.4674 || loss_t_decoder3/batch : 1.4445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7912 || loss_t_decoder2/batch : 0.7929 || loss_t_decoder3/batch : 1.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 29/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 29: 2.012178829738072-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           29\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.777090311050415\n",
      "Cumulative loss: 0.777090311050415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2351388931274414\n",
      "Cumulative loss: 2.0122292041778564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1596417427062988\n",
      "Cumulative loss: 3.1718709468841553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8429197072982788\n",
      "Cumulative loss: 4.0147905349731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2055667638778687\n",
      "Cumulative loss: 5.220357418060303\n",
      "------Final validation loss after epoch 29: 1.0440715551376343-------------\n",
      "Learning rate after epoch 29: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1705 || loss_t_decoder2/batch : 1.1045 || loss_t_decoder3/batch : 1.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):   3%|▎         | 1/35 [00:05<03:07,  5.51s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4859 || loss_t_decoder2/batch : 1.5032 || loss_t_decoder3/batch : 1.5607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):   6%|▌         | 2/35 [00:09<02:29,  4.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8264 || loss_t_decoder2/batch : 0.8834 || loss_t_decoder3/batch : 1.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):   9%|▊         | 3/35 [00:13<02:13,  4.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4787 || loss_t_decoder2/batch : 1.4745 || loss_t_decoder3/batch : 1.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  11%|█▏        | 4/35 [00:16<02:04,  4.02s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2342 || loss_t_decoder2/batch : 1.2860 || loss_t_decoder3/batch : 1.3943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  14%|█▍        | 5/35 [00:20<01:58,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2011 || loss_t_decoder2/batch : 1.2622 || loss_t_decoder3/batch : 1.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  17%|█▋        | 6/35 [00:24<01:52,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6868 || loss_t_decoder2/batch : 0.7243 || loss_t_decoder3/batch : 0.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  20%|██        | 7/35 [00:28<01:47,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7455 || loss_t_decoder2/batch : 0.7423 || loss_t_decoder3/batch : 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  23%|██▎       | 8/35 [00:32<01:43,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9785 || loss_t_decoder2/batch : 1.0607 || loss_t_decoder3/batch : 1.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  26%|██▌       | 9/35 [00:35<01:39,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1390 || loss_t_decoder2/batch : 1.2016 || loss_t_decoder3/batch : 1.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  29%|██▊       | 10/35 [00:39<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2872 || loss_t_decoder2/batch : 1.3065 || loss_t_decoder3/batch : 1.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1231 || loss_t_decoder2/batch : 1.0524 || loss_t_decoder3/batch : 1.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  34%|███▍      | 12/35 [00:47<01:27,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 2.0052 || loss_t_decoder2/batch : 2.0168 || loss_t_decoder3/batch : 2.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  37%|███▋      | 13/35 [00:51<01:23,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6778 || loss_t_decoder2/batch : 0.7465 || loss_t_decoder3/batch : 0.8858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  40%|████      | 14/35 [00:54<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3868 || loss_t_decoder2/batch : 1.4027 || loss_t_decoder3/batch : 1.5542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0684 || loss_t_decoder2/batch : 1.0999 || loss_t_decoder3/batch : 1.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  46%|████▌     | 16/35 [01:02<01:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2557 || loss_t_decoder2/batch : 1.3124 || loss_t_decoder3/batch : 1.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2954 || loss_t_decoder2/batch : 1.2347 || loss_t_decoder3/batch : 1.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1533 || loss_t_decoder2/batch : 1.1781 || loss_t_decoder3/batch : 1.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6479 || loss_t_decoder2/batch : 1.6415 || loss_t_decoder3/batch : 1.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8754 || loss_t_decoder2/batch : 0.9273 || loss_t_decoder3/batch : 1.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8613 || loss_t_decoder2/batch : 0.9461 || loss_t_decoder3/batch : 1.1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4545 || loss_t_decoder2/batch : 1.5076 || loss_t_decoder3/batch : 1.4680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  66%|██████▌   | 23/35 [01:28<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1077 || loss_t_decoder2/batch : 1.1521 || loss_t_decoder3/batch : 1.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9627 || loss_t_decoder2/batch : 0.9912 || loss_t_decoder3/batch : 1.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8728 || loss_t_decoder2/batch : 0.9062 || loss_t_decoder3/batch : 1.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9214 || loss_t_decoder2/batch : 0.9627 || loss_t_decoder3/batch : 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5229 || loss_t_decoder2/batch : 1.5319 || loss_t_decoder3/batch : 1.5973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  80%|████████  | 28/35 [01:47<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3513 || loss_t_decoder2/batch : 1.3702 || loss_t_decoder3/batch : 1.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9937 || loss_t_decoder2/batch : 1.0229 || loss_t_decoder3/batch : 1.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6861 || loss_t_decoder2/batch : 0.7315 || loss_t_decoder3/batch : 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8874 || loss_t_decoder2/batch : 0.9535 || loss_t_decoder3/batch : 1.0409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  91%|█████████▏| 32/35 [02:02<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8026 || loss_t_decoder2/batch : 0.8320 || loss_t_decoder3/batch : 0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3112 || loss_t_decoder2/batch : 1.3246 || loss_t_decoder3/batch : 1.4035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8409 || loss_t_decoder2/batch : 0.8681 || loss_t_decoder3/batch : 1.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 30/50): 100%|██████████| 35/35 [02:12<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 30: 2.0072019338607787-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           30\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7740281224250793\n",
      "Cumulative loss: 0.7740281224250793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2509483098983765\n",
      "Cumulative loss: 2.0249764919281006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1466845273971558\n",
      "Cumulative loss: 3.171660900115967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7911905646324158\n",
      "Cumulative loss: 3.9628515243530273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2215797901153564\n",
      "Cumulative loss: 5.184431076049805\n",
      "------Final validation loss after epoch 30: 1.036886215209961-------------\n",
      "Learning rate after epoch 30: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1916 || loss_t_decoder2/batch : 1.1679 || loss_t_decoder3/batch : 1.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):   3%|▎         | 1/35 [00:05<03:19,  5.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5058 || loss_t_decoder2/batch : 1.5263 || loss_t_decoder3/batch : 1.5732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):   6%|▌         | 2/35 [00:09<02:33,  4.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8363 || loss_t_decoder2/batch : 0.8773 || loss_t_decoder3/batch : 1.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):   9%|▊         | 3/35 [00:13<02:16,  4.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5720 || loss_t_decoder2/batch : 1.5756 || loss_t_decoder3/batch : 1.5453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  11%|█▏        | 4/35 [00:17<02:06,  4.07s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2270 || loss_t_decoder2/batch : 1.2733 || loss_t_decoder3/batch : 1.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  14%|█▍        | 5/35 [00:20<01:58,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3983 || loss_t_decoder2/batch : 1.4859 || loss_t_decoder3/batch : 1.4775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  17%|█▋        | 6/35 [00:24<01:53,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6774 || loss_t_decoder2/batch : 0.6993 || loss_t_decoder3/batch : 0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  20%|██        | 7/35 [00:28<01:48,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7690 || loss_t_decoder2/batch : 0.7556 || loss_t_decoder3/batch : 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0357 || loss_t_decoder2/batch : 1.0743 || loss_t_decoder3/batch : 1.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1538 || loss_t_decoder2/batch : 1.1747 || loss_t_decoder3/batch : 1.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  29%|██▊       | 10/35 [00:39<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2737 || loss_t_decoder2/batch : 1.3133 || loss_t_decoder3/batch : 1.3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0469 || loss_t_decoder2/batch : 1.0182 || loss_t_decoder3/batch : 1.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9678 || loss_t_decoder2/batch : 1.9473 || loss_t_decoder3/batch : 2.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6494 || loss_t_decoder2/batch : 0.7030 || loss_t_decoder3/batch : 0.8624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3001 || loss_t_decoder2/batch : 1.3139 || loss_t_decoder3/batch : 1.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0943 || loss_t_decoder2/batch : 1.1134 || loss_t_decoder3/batch : 1.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0371 || loss_t_decoder2/batch : 0.9903 || loss_t_decoder3/batch : 1.2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2094 || loss_t_decoder2/batch : 1.2102 || loss_t_decoder3/batch : 1.4243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1654 || loss_t_decoder2/batch : 1.2396 || loss_t_decoder3/batch : 1.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6803 || loss_t_decoder2/batch : 1.7839 || loss_t_decoder3/batch : 1.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8130 || loss_t_decoder2/batch : 0.9386 || loss_t_decoder3/batch : 1.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  60%|██████    | 21/35 [01:21<00:52,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8961 || loss_t_decoder2/batch : 0.9742 || loss_t_decoder3/batch : 1.1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4171 || loss_t_decoder2/batch : 1.4160 || loss_t_decoder3/batch : 1.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9524 || loss_t_decoder2/batch : 1.0568 || loss_t_decoder3/batch : 1.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9079 || loss_t_decoder2/batch : 0.9831 || loss_t_decoder3/batch : 1.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7722 || loss_t_decoder2/batch : 0.8489 || loss_t_decoder3/batch : 1.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6898 || loss_t_decoder2/batch : 0.8136 || loss_t_decoder3/batch : 0.9163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4563 || loss_t_decoder2/batch : 1.4943 || loss_t_decoder3/batch : 1.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3409 || loss_t_decoder2/batch : 1.3382 || loss_t_decoder3/batch : 1.3954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9279 || loss_t_decoder2/batch : 0.9840 || loss_t_decoder3/batch : 1.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6879 || loss_t_decoder2/batch : 0.7096 || loss_t_decoder3/batch : 0.8666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0146 || loss_t_decoder2/batch : 1.0247 || loss_t_decoder3/batch : 1.1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9201 || loss_t_decoder2/batch : 0.8335 || loss_t_decoder3/batch : 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2712 || loss_t_decoder2/batch : 1.2927 || loss_t_decoder3/batch : 1.3573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7878 || loss_t_decoder2/batch : 0.8523 || loss_t_decoder3/batch : 0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 31/50): 100%|██████████| 35/35 [02:13<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 31: 1.9818259137017387-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           31\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8940070271492004\n",
      "Cumulative loss: 0.8940070271492004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.3358738422393799\n",
      "Cumulative loss: 2.2298808097839355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.188976764678955\n",
      "Cumulative loss: 3.4188575744628906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9436047673225403\n",
      "Cumulative loss: 4.362462520599365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2263681888580322\n",
      "Cumulative loss: 5.588830947875977\n",
      "------Final validation loss after epoch 31: 1.117766261100769-------------\n",
      "Learning rate after epoch 31: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0153 || loss_t_decoder2/batch : 1.0358 || loss_t_decoder3/batch : 1.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):   3%|▎         | 1/35 [00:05<03:15,  5.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5270 || loss_t_decoder2/batch : 1.5341 || loss_t_decoder3/batch : 1.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):   6%|▌         | 2/35 [00:09<02:31,  4.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9633 || loss_t_decoder2/batch : 0.9656 || loss_t_decoder3/batch : 1.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):   9%|▊         | 3/35 [00:13<02:15,  4.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4967 || loss_t_decoder2/batch : 1.5483 || loss_t_decoder3/batch : 1.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  11%|█▏        | 4/35 [00:17<02:05,  4.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2765 || loss_t_decoder2/batch : 1.3012 || loss_t_decoder3/batch : 1.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  14%|█▍        | 5/35 [00:20<01:58,  3.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2288 || loss_t_decoder2/batch : 1.2589 || loss_t_decoder3/batch : 1.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  17%|█▋        | 6/35 [00:24<01:52,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7059 || loss_t_decoder2/batch : 0.7027 || loss_t_decoder3/batch : 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  20%|██        | 7/35 [00:28<01:47,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7636 || loss_t_decoder2/batch : 0.7454 || loss_t_decoder3/batch : 0.7866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0458 || loss_t_decoder2/batch : 1.0126 || loss_t_decoder3/batch : 1.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  26%|██▌       | 9/35 [00:36<01:39,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2846 || loss_t_decoder2/batch : 1.2073 || loss_t_decoder3/batch : 1.3128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  29%|██▊       | 10/35 [00:39<01:35,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2720 || loss_t_decoder2/batch : 1.3151 || loss_t_decoder3/batch : 1.4226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  31%|███▏      | 11/35 [00:43<01:31,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0159 || loss_t_decoder2/batch : 1.0955 || loss_t_decoder3/batch : 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  34%|███▍      | 12/35 [00:47<01:27,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9866 || loss_t_decoder2/batch : 1.9112 || loss_t_decoder3/batch : 2.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6413 || loss_t_decoder2/batch : 0.7121 || loss_t_decoder3/batch : 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  40%|████      | 14/35 [00:54<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2433 || loss_t_decoder2/batch : 1.3686 || loss_t_decoder3/batch : 1.4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0164 || loss_t_decoder2/batch : 0.9948 || loss_t_decoder3/batch : 1.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1138 || loss_t_decoder2/batch : 1.0501 || loss_t_decoder3/batch : 1.2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1519 || loss_t_decoder2/batch : 1.1246 || loss_t_decoder3/batch : 1.3224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0811 || loss_t_decoder2/batch : 1.0722 || loss_t_decoder3/batch : 1.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6296 || loss_t_decoder2/batch : 1.5805 || loss_t_decoder3/batch : 1.5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  57%|█████▋    | 20/35 [01:18<00:58,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8405 || loss_t_decoder2/batch : 0.9099 || loss_t_decoder3/batch : 1.0409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  60%|██████    | 21/35 [01:21<00:54,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8711 || loss_t_decoder2/batch : 0.9559 || loss_t_decoder3/batch : 1.0835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5261 || loss_t_decoder2/batch : 1.5045 || loss_t_decoder3/batch : 1.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1773 || loss_t_decoder2/batch : 1.1953 || loss_t_decoder3/batch : 1.2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9307 || loss_t_decoder2/batch : 0.9676 || loss_t_decoder3/batch : 1.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  71%|███████▏  | 25/35 [01:37<00:38,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7509 || loss_t_decoder2/batch : 0.8395 || loss_t_decoder3/batch : 1.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7845 || loss_t_decoder2/batch : 0.8559 || loss_t_decoder3/batch : 0.9273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5476 || loss_t_decoder2/batch : 1.5883 || loss_t_decoder3/batch : 1.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3020 || loss_t_decoder2/batch : 1.2883 || loss_t_decoder3/batch : 1.3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9233 || loss_t_decoder2/batch : 0.9601 || loss_t_decoder3/batch : 1.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7628 || loss_t_decoder2/batch : 0.8013 || loss_t_decoder3/batch : 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8251 || loss_t_decoder2/batch : 0.8651 || loss_t_decoder3/batch : 1.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1307 || loss_t_decoder2/batch : 1.0218 || loss_t_decoder3/batch : 1.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2621 || loss_t_decoder2/batch : 1.2789 || loss_t_decoder3/batch : 1.3368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7296 || loss_t_decoder2/batch : 0.7949 || loss_t_decoder3/batch : 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 32/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 32: 1.977095992224557-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           32\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.792586088180542\n",
      "Cumulative loss: 0.792586088180542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2329151630401611\n",
      "Cumulative loss: 2.025501251220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1207482814788818\n",
      "Cumulative loss: 3.146249532699585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8411269187927246\n",
      "Cumulative loss: 3.9873764514923096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.151430606842041\n",
      "Cumulative loss: 5.13880729675293\n",
      "------Final validation loss after epoch 32: 1.027761459350586-------------\n",
      "Learning rate after epoch 32: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1478 || loss_t_decoder2/batch : 1.0676 || loss_t_decoder3/batch : 1.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):   3%|▎         | 1/35 [00:05<03:16,  5.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4862 || loss_t_decoder2/batch : 1.5158 || loss_t_decoder3/batch : 1.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):   6%|▌         | 2/35 [00:09<02:32,  4.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8414 || loss_t_decoder2/batch : 0.8922 || loss_t_decoder3/batch : 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):   9%|▊         | 3/35 [00:13<02:15,  4.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3752 || loss_t_decoder2/batch : 1.4658 || loss_t_decoder3/batch : 1.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  11%|█▏        | 4/35 [00:17<02:05,  4.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2621 || loss_t_decoder2/batch : 1.3092 || loss_t_decoder3/batch : 1.4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  14%|█▍        | 5/35 [00:20<01:58,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1571 || loss_t_decoder2/batch : 1.2468 || loss_t_decoder3/batch : 1.3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  17%|█▋        | 6/35 [00:24<01:52,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6596 || loss_t_decoder2/batch : 0.7093 || loss_t_decoder3/batch : 0.8254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  20%|██        | 7/35 [00:28<01:48,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7412 || loss_t_decoder2/batch : 0.7517 || loss_t_decoder3/batch : 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0103 || loss_t_decoder2/batch : 1.0531 || loss_t_decoder3/batch : 1.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1636 || loss_t_decoder2/batch : 1.1728 || loss_t_decoder3/batch : 1.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  29%|██▊       | 10/35 [00:39<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2755 || loss_t_decoder2/batch : 1.2966 || loss_t_decoder3/batch : 1.3833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  31%|███▏      | 11/35 [00:43<01:31,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0562 || loss_t_decoder2/batch : 1.0007 || loss_t_decoder3/batch : 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9751 || loss_t_decoder2/batch : 1.9630 || loss_t_decoder3/batch : 2.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6352 || loss_t_decoder2/batch : 0.7164 || loss_t_decoder3/batch : 0.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  40%|████      | 14/35 [00:55<01:19,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1303 || loss_t_decoder2/batch : 1.2070 || loss_t_decoder3/batch : 1.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9811 || loss_t_decoder2/batch : 1.0271 || loss_t_decoder3/batch : 1.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  46%|████▌     | 16/35 [01:02<01:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1086 || loss_t_decoder2/batch : 1.0268 || loss_t_decoder3/batch : 1.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1643 || loss_t_decoder2/batch : 1.2247 || loss_t_decoder3/batch : 1.3476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0415 || loss_t_decoder2/batch : 1.0644 || loss_t_decoder3/batch : 1.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5861 || loss_t_decoder2/batch : 1.5560 || loss_t_decoder3/batch : 1.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8661 || loss_t_decoder2/batch : 0.9383 || loss_t_decoder3/batch : 1.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8634 || loss_t_decoder2/batch : 0.9525 || loss_t_decoder3/batch : 1.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4777 || loss_t_decoder2/batch : 1.4651 || loss_t_decoder3/batch : 1.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1183 || loss_t_decoder2/batch : 1.1011 || loss_t_decoder3/batch : 1.2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9257 || loss_t_decoder2/batch : 0.9466 || loss_t_decoder3/batch : 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8253 || loss_t_decoder2/batch : 0.8499 || loss_t_decoder3/batch : 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8498 || loss_t_decoder2/batch : 0.8408 || loss_t_decoder3/batch : 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5092 || loss_t_decoder2/batch : 1.4948 || loss_t_decoder3/batch : 1.5755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3461 || loss_t_decoder2/batch : 1.3790 || loss_t_decoder3/batch : 1.4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9851 || loss_t_decoder2/batch : 0.9905 || loss_t_decoder3/batch : 1.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7104 || loss_t_decoder2/batch : 0.8440 || loss_t_decoder3/batch : 0.9320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7732 || loss_t_decoder2/batch : 0.9021 || loss_t_decoder3/batch : 1.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9922 || loss_t_decoder2/batch : 1.0247 || loss_t_decoder3/batch : 1.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3755 || loss_t_decoder2/batch : 1.3516 || loss_t_decoder3/batch : 1.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7397 || loss_t_decoder2/batch : 0.7977 || loss_t_decoder3/batch : 0.9337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 33/50): 100%|██████████| 35/35 [02:13<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 33: 1.9504444871629987-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           33\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8859691619873047\n",
      "Cumulative loss: 0.8859691619873047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2410783767700195\n",
      "Cumulative loss: 2.127047538757324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1141258478164673\n",
      "Cumulative loss: 3.241173267364502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9923660755157471\n",
      "Cumulative loss: 4.233539581298828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1216137409210205\n",
      "Cumulative loss: 5.3551530838012695\n",
      "------Final validation loss after epoch 33: 1.071030616760254-------------\n",
      "Learning rate after epoch 33: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0788 || loss_t_decoder2/batch : 1.0051 || loss_t_decoder3/batch : 1.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):   3%|▎         | 1/35 [00:05<03:12,  5.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4844 || loss_t_decoder2/batch : 1.4931 || loss_t_decoder3/batch : 1.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):   6%|▌         | 2/35 [00:09<02:30,  4.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8432 || loss_t_decoder2/batch : 0.9034 || loss_t_decoder3/batch : 0.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):   9%|▊         | 3/35 [00:13<02:14,  4.20s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4399 || loss_t_decoder2/batch : 1.4654 || loss_t_decoder3/batch : 1.4811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  11%|█▏        | 4/35 [00:17<02:05,  4.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2455 || loss_t_decoder2/batch : 1.3005 || loss_t_decoder3/batch : 1.3946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  14%|█▍        | 5/35 [00:20<01:58,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2521 || loss_t_decoder2/batch : 1.2797 || loss_t_decoder3/batch : 1.3659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  17%|█▋        | 6/35 [00:24<01:53,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6661 || loss_t_decoder2/batch : 0.7223 || loss_t_decoder3/batch : 0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  20%|██        | 7/35 [00:28<01:48,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7167 || loss_t_decoder2/batch : 0.7687 || loss_t_decoder3/batch : 0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0515 || loss_t_decoder2/batch : 1.1132 || loss_t_decoder3/batch : 1.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  26%|██▌       | 9/35 [00:35<01:39,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1601 || loss_t_decoder2/batch : 1.1995 || loss_t_decoder3/batch : 1.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  29%|██▊       | 10/35 [00:39<01:35,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2801 || loss_t_decoder2/batch : 1.3180 || loss_t_decoder3/batch : 1.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  31%|███▏      | 11/35 [00:43<01:31,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0884 || loss_t_decoder2/batch : 1.0266 || loss_t_decoder3/batch : 1.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 2.0139 || loss_t_decoder2/batch : 2.0397 || loss_t_decoder3/batch : 2.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6342 || loss_t_decoder2/batch : 0.7118 || loss_t_decoder3/batch : 0.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  40%|████      | 14/35 [00:54<01:19,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2598 || loss_t_decoder2/batch : 1.2950 || loss_t_decoder3/batch : 1.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9949 || loss_t_decoder2/batch : 1.0591 || loss_t_decoder3/batch : 1.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9454 || loss_t_decoder2/batch : 0.9367 || loss_t_decoder3/batch : 1.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1802 || loss_t_decoder2/batch : 1.2083 || loss_t_decoder3/batch : 1.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1530 || loss_t_decoder2/batch : 1.1844 || loss_t_decoder3/batch : 1.2903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5937 || loss_t_decoder2/batch : 1.6115 || loss_t_decoder3/batch : 1.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8258 || loss_t_decoder2/batch : 0.8941 || loss_t_decoder3/batch : 1.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8419 || loss_t_decoder2/batch : 0.9335 || loss_t_decoder3/batch : 1.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4486 || loss_t_decoder2/batch : 1.4253 || loss_t_decoder3/batch : 1.4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  66%|██████▌   | 23/35 [01:28<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0681 || loss_t_decoder2/batch : 1.0815 || loss_t_decoder3/batch : 1.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9128 || loss_t_decoder2/batch : 0.9515 || loss_t_decoder3/batch : 1.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7285 || loss_t_decoder2/batch : 0.7703 || loss_t_decoder3/batch : 1.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8151 || loss_t_decoder2/batch : 0.8209 || loss_t_decoder3/batch : 0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5413 || loss_t_decoder2/batch : 1.5507 || loss_t_decoder3/batch : 1.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  80%|████████  | 28/35 [01:47<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3819 || loss_t_decoder2/batch : 1.3706 || loss_t_decoder3/batch : 1.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9589 || loss_t_decoder2/batch : 0.9660 || loss_t_decoder3/batch : 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7047 || loss_t_decoder2/batch : 0.7514 || loss_t_decoder3/batch : 0.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9030 || loss_t_decoder2/batch : 0.9374 || loss_t_decoder3/batch : 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1003 || loss_t_decoder2/batch : 0.9388 || loss_t_decoder3/batch : 0.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3694 || loss_t_decoder2/batch : 1.3468 || loss_t_decoder3/batch : 1.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7464 || loss_t_decoder2/batch : 0.8109 || loss_t_decoder3/batch : 0.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 34/50): 100%|██████████| 35/35 [02:12<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 34: 1.9595614807946342-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           34\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:10,  2.72s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7166241407394409\n",
      "Cumulative loss: 0.7166241407394409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2950295209884644\n",
      "Cumulative loss: 2.0116536617279053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1612019538879395\n",
      "Cumulative loss: 3.1728556156158447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9346394538879395\n",
      "Cumulative loss: 4.107495307922363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1470820903778076\n",
      "Cumulative loss: 5.25457763671875\n",
      "------Final validation loss after epoch 34: 1.0509155988693237-------------\n",
      "Learning rate after epoch 34: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0519 || loss_t_decoder2/batch : 1.1121 || loss_t_decoder3/batch : 1.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):   3%|▎         | 1/35 [00:05<03:22,  5.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4908 || loss_t_decoder2/batch : 1.5286 || loss_t_decoder3/batch : 1.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):   6%|▌         | 2/35 [00:09<02:35,  4.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8650 || loss_t_decoder2/batch : 0.9327 || loss_t_decoder3/batch : 1.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):   9%|▊         | 3/35 [00:13<02:17,  4.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3168 || loss_t_decoder2/batch : 1.3855 || loss_t_decoder3/batch : 1.4247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  11%|█▏        | 4/35 [00:17<02:06,  4.09s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2517 || loss_t_decoder2/batch : 1.2994 || loss_t_decoder3/batch : 1.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  14%|█▍        | 5/35 [00:21<01:59,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2510 || loss_t_decoder2/batch : 1.2191 || loss_t_decoder3/batch : 1.3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  17%|█▋        | 6/35 [00:24<01:54,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6618 || loss_t_decoder2/batch : 0.6691 || loss_t_decoder3/batch : 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  20%|██        | 7/35 [00:28<01:48,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7273 || loss_t_decoder2/batch : 0.7409 || loss_t_decoder3/batch : 0.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  23%|██▎       | 8/35 [00:32<01:44,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9832 || loss_t_decoder2/batch : 0.9933 || loss_t_decoder3/batch : 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  26%|██▌       | 9/35 [00:36<01:39,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1761 || loss_t_decoder2/batch : 1.1790 || loss_t_decoder3/batch : 1.2561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  29%|██▊       | 10/35 [00:40<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2839 || loss_t_decoder2/batch : 1.3020 || loss_t_decoder3/batch : 1.4238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  31%|███▏      | 11/35 [00:43<01:31,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0427 || loss_t_decoder2/batch : 1.0600 || loss_t_decoder3/batch : 1.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9408 || loss_t_decoder2/batch : 1.8482 || loss_t_decoder3/batch : 2.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  37%|███▋      | 13/35 [00:51<01:23,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6343 || loss_t_decoder2/batch : 0.7262 || loss_t_decoder3/batch : 0.8569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1478 || loss_t_decoder2/batch : 1.3157 || loss_t_decoder3/batch : 1.3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  43%|████▎     | 15/35 [00:59<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0102 || loss_t_decoder2/batch : 1.0469 || loss_t_decoder3/batch : 1.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0886 || loss_t_decoder2/batch : 1.0823 || loss_t_decoder3/batch : 1.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1329 || loss_t_decoder2/batch : 1.1849 || loss_t_decoder3/batch : 1.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9495 || loss_t_decoder2/batch : 0.9224 || loss_t_decoder3/batch : 1.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5486 || loss_t_decoder2/batch : 1.5300 || loss_t_decoder3/batch : 1.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8296 || loss_t_decoder2/batch : 0.9150 || loss_t_decoder3/batch : 1.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8369 || loss_t_decoder2/batch : 0.9107 || loss_t_decoder3/batch : 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5099 || loss_t_decoder2/batch : 1.4652 || loss_t_decoder3/batch : 1.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0838 || loss_t_decoder2/batch : 1.0740 || loss_t_decoder3/batch : 1.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9222 || loss_t_decoder2/batch : 0.9611 || loss_t_decoder3/batch : 1.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7446 || loss_t_decoder2/batch : 0.8312 || loss_t_decoder3/batch : 1.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7578 || loss_t_decoder2/batch : 0.8169 || loss_t_decoder3/batch : 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4697 || loss_t_decoder2/batch : 1.4418 || loss_t_decoder3/batch : 1.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  80%|████████  | 28/35 [01:48<00:26,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2979 || loss_t_decoder2/batch : 1.3163 || loss_t_decoder3/batch : 1.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8762 || loss_t_decoder2/batch : 0.9335 || loss_t_decoder3/batch : 1.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  86%|████████▌ | 30/35 [01:56<00:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7361 || loss_t_decoder2/batch : 0.7926 || loss_t_decoder3/batch : 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0004 || loss_t_decoder2/batch : 1.1147 || loss_t_decoder3/batch : 1.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0247 || loss_t_decoder2/batch : 0.9383 || loss_t_decoder3/batch : 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2678 || loss_t_decoder2/batch : 1.2754 || loss_t_decoder3/batch : 1.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8131 || loss_t_decoder2/batch : 0.8715 || loss_t_decoder3/batch : 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 35/50): 100%|██████████| 35/35 [02:13<00:00,  3.82s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 35: 1.9298081295830862-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           35\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.684815526008606\n",
      "Cumulative loss: 0.684815526008606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.237685203552246\n",
      "Cumulative loss: 1.922500729560852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1098644733428955\n",
      "Cumulative loss: 3.032365322113037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7678669691085815\n",
      "Cumulative loss: 3.800232410430908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1917641162872314\n",
      "Cumulative loss: 4.991996765136719\n",
      "------Final validation loss after epoch 35: 0.9983993768692017-------------\n",
      "Learning rate after epoch 35: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1427 || loss_t_decoder2/batch : 1.0782 || loss_t_decoder3/batch : 1.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):   3%|▎         | 1/35 [00:05<03:19,  5.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4596 || loss_t_decoder2/batch : 1.5049 || loss_t_decoder3/batch : 1.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):   6%|▌         | 2/35 [00:09<02:33,  4.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8387 || loss_t_decoder2/batch : 0.8992 || loss_t_decoder3/batch : 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):   9%|▊         | 3/35 [00:13<02:16,  4.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3716 || loss_t_decoder2/batch : 1.4235 || loss_t_decoder3/batch : 1.4492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  11%|█▏        | 4/35 [00:17<02:06,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2520 || loss_t_decoder2/batch : 1.2976 || loss_t_decoder3/batch : 1.3661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  14%|█▍        | 5/35 [00:21<01:59,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1600 || loss_t_decoder2/batch : 1.2072 || loss_t_decoder3/batch : 1.2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  17%|█▋        | 6/35 [00:24<01:53,  3.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6853 || loss_t_decoder2/batch : 0.7031 || loss_t_decoder3/batch : 0.8469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  20%|██        | 7/35 [00:28<01:48,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7177 || loss_t_decoder2/batch : 0.7361 || loss_t_decoder3/batch : 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  23%|██▎       | 8/35 [00:32<01:43,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9228 || loss_t_decoder2/batch : 0.9780 || loss_t_decoder3/batch : 1.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1866 || loss_t_decoder2/batch : 1.1859 || loss_t_decoder3/batch : 1.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2904 || loss_t_decoder2/batch : 1.3108 || loss_t_decoder3/batch : 1.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1372 || loss_t_decoder2/batch : 1.2119 || loss_t_decoder3/batch : 1.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9701 || loss_t_decoder2/batch : 1.9600 || loss_t_decoder3/batch : 2.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6339 || loss_t_decoder2/batch : 0.7325 || loss_t_decoder3/batch : 0.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1815 || loss_t_decoder2/batch : 1.0816 || loss_t_decoder3/batch : 1.3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9446 || loss_t_decoder2/batch : 0.9760 || loss_t_decoder3/batch : 1.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1227 || loss_t_decoder2/batch : 1.0064 || loss_t_decoder3/batch : 1.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1502 || loss_t_decoder2/batch : 1.1551 || loss_t_decoder3/batch : 1.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9797 || loss_t_decoder2/batch : 0.9786 || loss_t_decoder3/batch : 1.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5296 || loss_t_decoder2/batch : 1.5140 || loss_t_decoder3/batch : 1.5133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8554 || loss_t_decoder2/batch : 0.9197 || loss_t_decoder3/batch : 1.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8669 || loss_t_decoder2/batch : 0.9194 || loss_t_decoder3/batch : 1.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4295 || loss_t_decoder2/batch : 1.4065 || loss_t_decoder3/batch : 1.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0645 || loss_t_decoder2/batch : 1.0546 || loss_t_decoder3/batch : 1.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9205 || loss_t_decoder2/batch : 0.9364 || loss_t_decoder3/batch : 1.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7606 || loss_t_decoder2/batch : 0.8261 || loss_t_decoder3/batch : 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7974 || loss_t_decoder2/batch : 0.8093 || loss_t_decoder3/batch : 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3993 || loss_t_decoder2/batch : 1.4076 || loss_t_decoder3/batch : 1.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  80%|████████  | 28/35 [01:48<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2944 || loss_t_decoder2/batch : 1.2900 || loss_t_decoder3/batch : 1.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9190 || loss_t_decoder2/batch : 0.9095 || loss_t_decoder3/batch : 1.0498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6795 || loss_t_decoder2/batch : 0.7880 || loss_t_decoder3/batch : 0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7426 || loss_t_decoder2/batch : 0.8928 || loss_t_decoder3/batch : 1.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9512 || loss_t_decoder2/batch : 0.9878 || loss_t_decoder3/batch : 1.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2375 || loss_t_decoder2/batch : 1.2536 || loss_t_decoder3/batch : 1.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7680 || loss_t_decoder2/batch : 0.8427 || loss_t_decoder3/batch : 0.9196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 36/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 36: 1.90931864125388-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           36\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6920093297958374\n",
      "Cumulative loss: 0.6920093297958374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2711759805679321\n",
      "Cumulative loss: 1.9631853103637695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0877718925476074\n",
      "Cumulative loss: 3.050957202911377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7413798570632935\n",
      "Cumulative loss: 3.792336940765381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1551990509033203\n",
      "Cumulative loss: 4.947535991668701\n",
      "------Final validation loss after epoch 36: 0.9895071983337402-------------\n",
      "Learning rate after epoch 36: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0680 || loss_t_decoder2/batch : 1.0345 || loss_t_decoder3/batch : 1.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):   3%|▎         | 1/35 [00:05<03:09,  5.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4747 || loss_t_decoder2/batch : 1.5156 || loss_t_decoder3/batch : 1.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):   6%|▌         | 2/35 [00:09<02:40,  4.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8580 || loss_t_decoder2/batch : 0.9227 || loss_t_decoder3/batch : 1.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):   9%|▊         | 3/35 [00:13<02:19,  4.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2740 || loss_t_decoder2/batch : 1.3604 || loss_t_decoder3/batch : 1.3596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  11%|█▏        | 4/35 [00:17<02:08,  4.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2522 || loss_t_decoder2/batch : 1.3025 || loss_t_decoder3/batch : 1.3862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  14%|█▍        | 5/35 [00:21<02:02,  4.10s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1300 || loss_t_decoder2/batch : 1.1988 || loss_t_decoder3/batch : 1.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  17%|█▋        | 6/35 [00:25<01:55,  3.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6430 || loss_t_decoder2/batch : 0.6739 || loss_t_decoder3/batch : 0.8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  20%|██        | 7/35 [00:29<01:49,  3.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6948 || loss_t_decoder2/batch : 0.7157 || loss_t_decoder3/batch : 0.8095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  23%|██▎       | 8/35 [00:32<01:44,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9300 || loss_t_decoder2/batch : 1.0205 || loss_t_decoder3/batch : 1.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  26%|██▌       | 9/35 [00:36<01:40,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1200 || loss_t_decoder2/batch : 1.1644 || loss_t_decoder3/batch : 1.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  29%|██▊       | 10/35 [00:40<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2606 || loss_t_decoder2/batch : 1.3031 || loss_t_decoder3/batch : 1.3716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  31%|███▏      | 11/35 [00:44<01:31,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0818 || loss_t_decoder2/batch : 0.9133 || loss_t_decoder3/batch : 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  34%|███▍      | 12/35 [00:48<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9651 || loss_t_decoder2/batch : 1.9451 || loss_t_decoder3/batch : 2.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6490 || loss_t_decoder2/batch : 0.7477 || loss_t_decoder3/batch : 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  40%|████      | 14/35 [00:55<01:19,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1702 || loss_t_decoder2/batch : 1.2956 || loss_t_decoder3/batch : 1.3848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  43%|████▎     | 15/35 [00:59<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9662 || loss_t_decoder2/batch : 1.0052 || loss_t_decoder3/batch : 1.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  46%|████▌     | 16/35 [01:03<01:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9614 || loss_t_decoder2/batch : 0.9674 || loss_t_decoder3/batch : 1.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1515 || loss_t_decoder2/batch : 1.1728 || loss_t_decoder3/batch : 1.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  51%|█████▏    | 18/35 [01:11<01:07,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9925 || loss_t_decoder2/batch : 1.0114 || loss_t_decoder3/batch : 1.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  54%|█████▍    | 19/35 [01:15<01:02,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5108 || loss_t_decoder2/batch : 1.4940 || loss_t_decoder3/batch : 1.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  57%|█████▋    | 20/35 [01:18<00:58,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8647 || loss_t_decoder2/batch : 0.9124 || loss_t_decoder3/batch : 1.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  60%|██████    | 21/35 [01:22<00:53,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8233 || loss_t_decoder2/batch : 0.8996 || loss_t_decoder3/batch : 1.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  63%|██████▎   | 22/35 [01:26<00:49,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4065 || loss_t_decoder2/batch : 1.4101 || loss_t_decoder3/batch : 1.4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  66%|██████▌   | 23/35 [01:30<00:45,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0645 || loss_t_decoder2/batch : 1.0563 || loss_t_decoder3/batch : 1.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  69%|██████▊   | 24/35 [01:34<00:41,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9416 || loss_t_decoder2/batch : 1.0143 || loss_t_decoder3/batch : 1.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  71%|███████▏  | 25/35 [01:37<00:38,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8030 || loss_t_decoder2/batch : 0.8396 || loss_t_decoder3/batch : 1.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8113 || loss_t_decoder2/batch : 0.8169 || loss_t_decoder3/batch : 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  77%|███████▋  | 27/35 [01:45<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4344 || loss_t_decoder2/batch : 1.4843 || loss_t_decoder3/batch : 1.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  80%|████████  | 28/35 [01:49<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2934 || loss_t_decoder2/batch : 1.3048 || loss_t_decoder3/batch : 1.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  83%|████████▎ | 29/35 [01:53<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9459 || loss_t_decoder2/batch : 0.9516 || loss_t_decoder3/batch : 1.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6497 || loss_t_decoder2/batch : 0.7028 || loss_t_decoder3/batch : 0.8054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  89%|████████▊ | 31/35 [02:00<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7502 || loss_t_decoder2/batch : 0.8138 || loss_t_decoder3/batch : 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  91%|█████████▏| 32/35 [02:04<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7481 || loss_t_decoder2/batch : 0.7590 || loss_t_decoder3/batch : 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  94%|█████████▍| 33/35 [02:08<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3542 || loss_t_decoder2/batch : 1.3548 || loss_t_decoder3/batch : 1.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7459 || loss_t_decoder2/batch : 0.8434 || loss_t_decoder3/batch : 0.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 37/50): 100%|██████████| 35/35 [02:14<00:00,  3.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 37: 1.8884233679090228-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           37\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:10,  2.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2950141429901123\n",
      "Cumulative loss: 1.2950141429901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2222732305526733\n",
      "Cumulative loss: 2.517287254333496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.086596131324768\n",
      "Cumulative loss: 3.6038832664489746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8665280342102051\n",
      "Cumulative loss: 4.47041130065918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.197058916091919\n",
      "Cumulative loss: 5.6674699783325195\n",
      "------Final validation loss after epoch 37: 1.1334940195083618-------------\n",
      "Learning rate after epoch 37: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2770 || loss_t_decoder2/batch : 1.2184 || loss_t_decoder3/batch : 1.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):   3%|▎         | 1/35 [00:05<03:22,  5.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4483 || loss_t_decoder2/batch : 1.4610 || loss_t_decoder3/batch : 1.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):   6%|▌         | 2/35 [00:09<02:34,  4.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7692 || loss_t_decoder2/batch : 0.8519 || loss_t_decoder3/batch : 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):   9%|▊         | 3/35 [00:13<02:16,  4.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2944 || loss_t_decoder2/batch : 1.3479 || loss_t_decoder3/batch : 1.3774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  11%|█▏        | 4/35 [00:17<02:06,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2298 || loss_t_decoder2/batch : 1.2753 || loss_t_decoder3/batch : 1.3560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  14%|█▍        | 5/35 [00:21<01:59,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3713 || loss_t_decoder2/batch : 1.3585 || loss_t_decoder3/batch : 1.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  17%|█▋        | 6/35 [00:24<01:53,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6643 || loss_t_decoder2/batch : 0.6866 || loss_t_decoder3/batch : 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  20%|██        | 7/35 [00:28<01:48,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6509 || loss_t_decoder2/batch : 0.6809 || loss_t_decoder3/batch : 0.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9705 || loss_t_decoder2/batch : 1.0276 || loss_t_decoder3/batch : 1.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1259 || loss_t_decoder2/batch : 1.1235 || loss_t_decoder3/batch : 1.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2608 || loss_t_decoder2/batch : 1.2904 || loss_t_decoder3/batch : 1.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  31%|███▏      | 11/35 [00:44<01:33,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9644 || loss_t_decoder2/batch : 0.9040 || loss_t_decoder3/batch : 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  34%|███▍      | 12/35 [00:47<01:28,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9845 || loss_t_decoder2/batch : 1.9969 || loss_t_decoder3/batch : 2.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  37%|███▋      | 13/35 [00:51<01:24,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6542 || loss_t_decoder2/batch : 0.7800 || loss_t_decoder3/batch : 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  40%|████      | 14/35 [00:55<01:20,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1861 || loss_t_decoder2/batch : 1.4606 || loss_t_decoder3/batch : 1.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  43%|████▎     | 15/35 [00:59<01:16,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0000 || loss_t_decoder2/batch : 1.0205 || loss_t_decoder3/batch : 1.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0231 || loss_t_decoder2/batch : 1.0665 || loss_t_decoder3/batch : 1.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1411 || loss_t_decoder2/batch : 1.1205 || loss_t_decoder3/batch : 1.2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9318 || loss_t_decoder2/batch : 0.9463 || loss_t_decoder3/batch : 1.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5095 || loss_t_decoder2/batch : 1.5183 || loss_t_decoder3/batch : 1.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8405 || loss_t_decoder2/batch : 0.9078 || loss_t_decoder3/batch : 1.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8702 || loss_t_decoder2/batch : 0.9110 || loss_t_decoder3/batch : 1.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4655 || loss_t_decoder2/batch : 1.4614 || loss_t_decoder3/batch : 1.4887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0927 || loss_t_decoder2/batch : 1.0873 || loss_t_decoder3/batch : 1.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9512 || loss_t_decoder2/batch : 0.9806 || loss_t_decoder3/batch : 1.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8503 || loss_t_decoder2/batch : 0.9094 || loss_t_decoder3/batch : 0.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8259 || loss_t_decoder2/batch : 0.8572 || loss_t_decoder3/batch : 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4749 || loss_t_decoder2/batch : 1.4725 || loss_t_decoder3/batch : 1.5552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  80%|████████  | 28/35 [01:48<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3611 || loss_t_decoder2/batch : 1.4001 || loss_t_decoder3/batch : 1.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9477 || loss_t_decoder2/batch : 0.9928 || loss_t_decoder3/batch : 1.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7334 || loss_t_decoder2/batch : 0.7714 || loss_t_decoder3/batch : 0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0032 || loss_t_decoder2/batch : 1.0610 || loss_t_decoder3/batch : 1.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9748 || loss_t_decoder2/batch : 0.8977 || loss_t_decoder3/batch : 1.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2461 || loss_t_decoder2/batch : 1.2725 || loss_t_decoder3/batch : 1.3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7152 || loss_t_decoder2/batch : 0.8180 || loss_t_decoder3/batch : 0.9261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 38/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 38: 1.9364900623049055-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           38\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.808445394039154\n",
      "Cumulative loss: 0.808445394039154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2606008052825928\n",
      "Cumulative loss: 2.0690462589263916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1097257137298584\n",
      "Cumulative loss: 3.17877197265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8183388710021973\n",
      "Cumulative loss: 3.9971108436584473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1497290134429932\n",
      "Cumulative loss: 5.1468400955200195\n",
      "------Final validation loss after epoch 38: 1.0293680429458618-------------\n",
      "Learning rate after epoch 38: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1275 || loss_t_decoder2/batch : 1.1280 || loss_t_decoder3/batch : 1.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):   3%|▎         | 1/35 [00:05<03:16,  5.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4499 || loss_t_decoder2/batch : 1.5051 || loss_t_decoder3/batch : 1.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):   6%|▌         | 2/35 [00:09<02:31,  4.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8334 || loss_t_decoder2/batch : 0.9398 || loss_t_decoder3/batch : 0.9441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):   9%|▊         | 3/35 [00:13<02:17,  4.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3288 || loss_t_decoder2/batch : 1.3973 || loss_t_decoder3/batch : 1.4635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  11%|█▏        | 4/35 [00:17<02:06,  4.09s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2611 || loss_t_decoder2/batch : 1.3219 || loss_t_decoder3/batch : 1.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  14%|█▍        | 5/35 [00:21<02:02,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2252 || loss_t_decoder2/batch : 1.2522 || loss_t_decoder3/batch : 1.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  17%|█▋        | 6/35 [00:25<01:55,  3.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6516 || loss_t_decoder2/batch : 0.6757 || loss_t_decoder3/batch : 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  20%|██        | 7/35 [00:28<01:49,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7072 || loss_t_decoder2/batch : 0.7238 || loss_t_decoder3/batch : 0.7704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  23%|██▎       | 8/35 [00:32<01:44,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9464 || loss_t_decoder2/batch : 0.9901 || loss_t_decoder3/batch : 1.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  26%|██▌       | 9/35 [00:36<01:40,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2292 || loss_t_decoder2/batch : 1.2430 || loss_t_decoder3/batch : 1.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  29%|██▊       | 10/35 [00:40<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2582 || loss_t_decoder2/batch : 1.2813 || loss_t_decoder3/batch : 1.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  31%|███▏      | 11/35 [00:44<01:33,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2682 || loss_t_decoder2/batch : 1.2516 || loss_t_decoder3/batch : 1.2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  34%|███▍      | 12/35 [00:48<01:28,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9188 || loss_t_decoder2/batch : 1.9050 || loss_t_decoder3/batch : 1.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  37%|███▋      | 13/35 [00:51<01:24,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6179 || loss_t_decoder2/batch : 0.7148 || loss_t_decoder3/batch : 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  40%|████      | 14/35 [00:55<01:20,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1082 || loss_t_decoder2/batch : 1.1928 || loss_t_decoder3/batch : 1.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  43%|████▎     | 15/35 [00:59<01:16,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9892 || loss_t_decoder2/batch : 1.0672 || loss_t_decoder3/batch : 1.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  46%|████▌     | 16/35 [01:03<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1479 || loss_t_decoder2/batch : 1.0881 || loss_t_decoder3/batch : 1.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2305 || loss_t_decoder2/batch : 1.1609 || loss_t_decoder3/batch : 1.2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2407 || loss_t_decoder2/batch : 1.2873 || loss_t_decoder3/batch : 1.4081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9044 || loss_t_decoder2/batch : 2.0800 || loss_t_decoder3/batch : 2.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7888 || loss_t_decoder2/batch : 0.9297 || loss_t_decoder3/batch : 1.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  60%|██████    | 21/35 [01:22<00:52,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9144 || loss_t_decoder2/batch : 1.0124 || loss_t_decoder3/batch : 1.1895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6402 || loss_t_decoder2/batch : 1.5809 || loss_t_decoder3/batch : 1.5716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1616 || loss_t_decoder2/batch : 1.1472 || loss_t_decoder3/batch : 1.2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9777 || loss_t_decoder2/batch : 0.9915 || loss_t_decoder3/batch : 1.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8412 || loss_t_decoder2/batch : 0.8866 || loss_t_decoder3/batch : 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8737 || loss_t_decoder2/batch : 0.8946 || loss_t_decoder3/batch : 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6267 || loss_t_decoder2/batch : 1.6077 || loss_t_decoder3/batch : 1.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4255 || loss_t_decoder2/batch : 1.4413 || loss_t_decoder3/batch : 1.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9506 || loss_t_decoder2/batch : 0.9550 || loss_t_decoder3/batch : 1.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6539 || loss_t_decoder2/batch : 0.6916 || loss_t_decoder3/batch : 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1846 || loss_t_decoder2/batch : 1.2102 || loss_t_decoder3/batch : 1.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8141 || loss_t_decoder2/batch : 0.8469 || loss_t_decoder3/batch : 0.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2410 || loss_t_decoder2/batch : 1.2902 || loss_t_decoder3/batch : 1.3560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7858 || loss_t_decoder2/batch : 0.8463 || loss_t_decoder3/batch : 0.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 39/50): 100%|██████████| 35/35 [02:13<00:00,  3.82s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 39: 2.0122735568455288-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           39\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:10,  2.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9052727222442627\n",
      "Cumulative loss: 0.9052727222442627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2616857290267944\n",
      "Cumulative loss: 2.1669583320617676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1342755556106567\n",
      "Cumulative loss: 3.3012337684631348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8292719125747681\n",
      "Cumulative loss: 4.130505561828613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0669933557510376\n",
      "Cumulative loss: 5.197498798370361\n",
      "------Final validation loss after epoch 39: 1.0394997596740723-------------\n",
      "Learning rate after epoch 39: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1212 || loss_t_decoder2/batch : 1.2178 || loss_t_decoder3/batch : 1.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):   3%|▎         | 1/35 [00:05<03:20,  5.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5975 || loss_t_decoder2/batch : 1.5694 || loss_t_decoder3/batch : 1.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):   6%|▌         | 2/35 [00:09<02:33,  4.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8493 || loss_t_decoder2/batch : 0.8780 || loss_t_decoder3/batch : 0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):   9%|▊         | 3/35 [00:13<02:16,  4.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.6159 || loss_t_decoder2/batch : 1.6073 || loss_t_decoder3/batch : 1.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  11%|█▏        | 4/35 [00:17<02:06,  4.07s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2665 || loss_t_decoder2/batch : 1.3081 || loss_t_decoder3/batch : 1.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  14%|█▍        | 5/35 [00:21<02:01,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2900 || loss_t_decoder2/batch : 1.3056 || loss_t_decoder3/batch : 1.3954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  17%|█▋        | 6/35 [00:25<01:54,  3.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6763 || loss_t_decoder2/batch : 0.7534 || loss_t_decoder3/batch : 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  20%|██        | 7/35 [00:28<01:49,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7296 || loss_t_decoder2/batch : 0.7465 || loss_t_decoder3/batch : 0.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  23%|██▎       | 8/35 [00:32<01:44,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0084 || loss_t_decoder2/batch : 1.0504 || loss_t_decoder3/batch : 1.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  26%|██▌       | 9/35 [00:36<01:40,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1414 || loss_t_decoder2/batch : 1.1461 || loss_t_decoder3/batch : 1.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2800 || loss_t_decoder2/batch : 1.3146 || loss_t_decoder3/batch : 1.4038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  31%|███▏      | 11/35 [00:43<01:31,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9697 || loss_t_decoder2/batch : 0.9358 || loss_t_decoder3/batch : 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9521 || loss_t_decoder2/batch : 1.9567 || loss_t_decoder3/batch : 2.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6218 || loss_t_decoder2/batch : 0.7199 || loss_t_decoder3/batch : 0.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0980 || loss_t_decoder2/batch : 1.2952 || loss_t_decoder3/batch : 1.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  43%|████▎     | 15/35 [00:59<01:16,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9213 || loss_t_decoder2/batch : 0.9831 || loss_t_decoder3/batch : 1.1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0578 || loss_t_decoder2/batch : 0.9925 || loss_t_decoder3/batch : 1.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  49%|████▊     | 17/35 [01:06<01:08,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1171 || loss_t_decoder2/batch : 1.0541 || loss_t_decoder3/batch : 1.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0706 || loss_t_decoder2/batch : 1.0632 || loss_t_decoder3/batch : 1.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5928 || loss_t_decoder2/batch : 1.5445 || loss_t_decoder3/batch : 1.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8060 || loss_t_decoder2/batch : 0.8906 || loss_t_decoder3/batch : 1.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8436 || loss_t_decoder2/batch : 0.9258 || loss_t_decoder3/batch : 1.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4807 || loss_t_decoder2/batch : 1.4702 || loss_t_decoder3/batch : 1.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0830 || loss_t_decoder2/batch : 1.0920 || loss_t_decoder3/batch : 1.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9292 || loss_t_decoder2/batch : 0.9627 || loss_t_decoder3/batch : 1.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8062 || loss_t_decoder2/batch : 0.8603 || loss_t_decoder3/batch : 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8346 || loss_t_decoder2/batch : 0.8837 || loss_t_decoder3/batch : 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4192 || loss_t_decoder2/batch : 1.4259 || loss_t_decoder3/batch : 1.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3098 || loss_t_decoder2/batch : 1.3509 || loss_t_decoder3/batch : 1.3773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9435 || loss_t_decoder2/batch : 0.9883 || loss_t_decoder3/batch : 1.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6626 || loss_t_decoder2/batch : 0.7262 || loss_t_decoder3/batch : 0.8563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8899 || loss_t_decoder2/batch : 0.9873 || loss_t_decoder3/batch : 1.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8587 || loss_t_decoder2/batch : 0.9028 || loss_t_decoder3/batch : 1.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2482 || loss_t_decoder2/batch : 1.2788 || loss_t_decoder3/batch : 1.3476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7625 || loss_t_decoder2/batch : 0.8002 || loss_t_decoder3/batch : 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 40/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 40: 1.9430635213851928-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           40\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.736585259437561\n",
      "Cumulative loss: 0.736585259437561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2499184608459473\n",
      "Cumulative loss: 1.9865037202835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1075206995010376\n",
      "Cumulative loss: 3.094024419784546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7546201944351196\n",
      "Cumulative loss: 3.848644733428955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.122664213180542\n",
      "Cumulative loss: 4.971308708190918\n",
      "------Final validation loss after epoch 40: 0.9942617416381836-------------\n",
      "Learning rate after epoch 40: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0655 || loss_t_decoder2/batch : 1.0491 || loss_t_decoder3/batch : 1.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):   3%|▎         | 1/35 [00:05<03:20,  5.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4419 || loss_t_decoder2/batch : 1.4534 || loss_t_decoder3/batch : 1.4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):   6%|▌         | 2/35 [00:09<02:33,  4.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8499 || loss_t_decoder2/batch : 0.9021 || loss_t_decoder3/batch : 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):   9%|▊         | 3/35 [00:13<02:16,  4.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4725 || loss_t_decoder2/batch : 1.5248 || loss_t_decoder3/batch : 1.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  11%|█▏        | 4/35 [00:17<02:06,  4.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2483 || loss_t_decoder2/batch : 1.2829 || loss_t_decoder3/batch : 1.3548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  14%|█▍        | 5/35 [00:21<02:02,  4.07s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2021 || loss_t_decoder2/batch : 1.2482 || loss_t_decoder3/batch : 1.2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  17%|█▋        | 6/35 [00:25<01:55,  3.97s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6210 || loss_t_decoder2/batch : 0.6722 || loss_t_decoder3/batch : 0.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  20%|██        | 7/35 [00:28<01:49,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6756 || loss_t_decoder2/batch : 0.7031 || loss_t_decoder3/batch : 0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  23%|██▎       | 8/35 [00:32<01:44,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9542 || loss_t_decoder2/batch : 1.0101 || loss_t_decoder3/batch : 1.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1583 || loss_t_decoder2/batch : 1.1883 || loss_t_decoder3/batch : 1.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2747 || loss_t_decoder2/batch : 1.3009 || loss_t_decoder3/batch : 1.3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  31%|███▏      | 11/35 [00:44<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9772 || loss_t_decoder2/batch : 0.8875 || loss_t_decoder3/batch : 0.9413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9226 || loss_t_decoder2/batch : 1.9424 || loss_t_decoder3/batch : 2.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  37%|███▋      | 13/35 [00:51<01:23,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6504 || loss_t_decoder2/batch : 0.7503 || loss_t_decoder3/batch : 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  40%|████      | 14/35 [00:55<01:19,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1878 || loss_t_decoder2/batch : 1.3803 || loss_t_decoder3/batch : 1.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  43%|████▎     | 15/35 [00:59<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9627 || loss_t_decoder2/batch : 1.0288 || loss_t_decoder3/batch : 1.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9943 || loss_t_decoder2/batch : 1.0003 || loss_t_decoder3/batch : 1.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9788 || loss_t_decoder2/batch : 1.0149 || loss_t_decoder3/batch : 1.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0529 || loss_t_decoder2/batch : 1.0680 || loss_t_decoder3/batch : 1.1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4829 || loss_t_decoder2/batch : 1.4811 || loss_t_decoder3/batch : 1.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8195 || loss_t_decoder2/batch : 0.9046 || loss_t_decoder3/batch : 1.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8360 || loss_t_decoder2/batch : 0.9220 || loss_t_decoder3/batch : 1.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4366 || loss_t_decoder2/batch : 1.4405 || loss_t_decoder3/batch : 1.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2140 || loss_t_decoder2/batch : 1.1801 || loss_t_decoder3/batch : 1.3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9656 || loss_t_decoder2/batch : 1.0144 || loss_t_decoder3/batch : 1.0813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7770 || loss_t_decoder2/batch : 0.8628 || loss_t_decoder3/batch : 0.9804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7800 || loss_t_decoder2/batch : 0.8122 || loss_t_decoder3/batch : 0.9105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4148 || loss_t_decoder2/batch : 1.4653 || loss_t_decoder3/batch : 1.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  80%|████████  | 28/35 [01:48<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3448 || loss_t_decoder2/batch : 1.3550 || loss_t_decoder3/batch : 1.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9304 || loss_t_decoder2/batch : 0.9581 || loss_t_decoder3/batch : 1.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7466 || loss_t_decoder2/batch : 0.8016 || loss_t_decoder3/batch : 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8533 || loss_t_decoder2/batch : 0.9071 || loss_t_decoder3/batch : 1.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8877 || loss_t_decoder2/batch : 0.8786 || loss_t_decoder3/batch : 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2880 || loss_t_decoder2/batch : 1.3009 || loss_t_decoder3/batch : 1.3429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7814 || loss_t_decoder2/batch : 0.9122 || loss_t_decoder3/batch : 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 41/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 41: 1.9125332525798253-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           41\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:10,  2.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6957669258117676\n",
      "Cumulative loss: 0.6957669258117676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2889724969863892\n",
      "Cumulative loss: 1.9847394227981567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.43s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.124248743057251\n",
      "Cumulative loss: 3.1089882850646973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7793009877204895\n",
      "Cumulative loss: 3.888289213180542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2397234439849854\n",
      "Cumulative loss: 5.128012657165527\n",
      "------Final validation loss after epoch 41: 1.0256025791168213-------------\n",
      "Learning rate after epoch 41: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0069 || loss_t_decoder2/batch : 1.0575 || loss_t_decoder3/batch : 1.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):   3%|▎         | 1/35 [00:05<03:16,  5.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4541 || loss_t_decoder2/batch : 1.5327 || loss_t_decoder3/batch : 1.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):   6%|▌         | 2/35 [00:09<02:32,  4.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8871 || loss_t_decoder2/batch : 0.9908 || loss_t_decoder3/batch : 1.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):   9%|▊         | 3/35 [00:13<02:18,  4.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3034 || loss_t_decoder2/batch : 1.3884 || loss_t_decoder3/batch : 1.4162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  11%|█▏        | 4/35 [00:17<02:07,  4.12s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2435 || loss_t_decoder2/batch : 1.3132 || loss_t_decoder3/batch : 1.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  14%|█▍        | 5/35 [00:21<02:00,  4.01s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3017 || loss_t_decoder2/batch : 1.3247 || loss_t_decoder3/batch : 1.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  17%|█▋        | 6/35 [00:24<01:54,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6411 || loss_t_decoder2/batch : 0.6823 || loss_t_decoder3/batch : 0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  20%|██        | 7/35 [00:28<01:48,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7004 || loss_t_decoder2/batch : 0.7347 || loss_t_decoder3/batch : 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  23%|██▎       | 8/35 [00:32<01:44,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9056 || loss_t_decoder2/batch : 1.0306 || loss_t_decoder3/batch : 1.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0736 || loss_t_decoder2/batch : 1.1535 || loss_t_decoder3/batch : 1.2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  29%|██▊       | 10/35 [00:40<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2620 || loss_t_decoder2/batch : 1.2888 || loss_t_decoder3/batch : 1.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1167 || loss_t_decoder2/batch : 0.8731 || loss_t_decoder3/batch : 0.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  34%|███▍      | 12/35 [00:48<01:31,  4.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9730 || loss_t_decoder2/batch : 1.9831 || loss_t_decoder3/batch : 2.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  37%|███▋      | 13/35 [00:52<01:26,  3.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6183 || loss_t_decoder2/batch : 0.7690 || loss_t_decoder3/batch : 0.8789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  40%|████      | 14/35 [00:55<01:21,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4633 || loss_t_decoder2/batch : 1.5190 || loss_t_decoder3/batch : 1.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  43%|████▎     | 15/35 [00:59<01:17,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9341 || loss_t_decoder2/batch : 0.9287 || loss_t_decoder3/batch : 1.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  46%|████▌     | 16/35 [01:03<01:12,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9653 || loss_t_decoder2/batch : 0.9899 || loss_t_decoder3/batch : 1.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  49%|████▊     | 17/35 [01:07<01:08,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1490 || loss_t_decoder2/batch : 1.1716 || loss_t_decoder3/batch : 1.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  51%|█████▏    | 18/35 [01:11<01:05,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9736 || loss_t_decoder2/batch : 1.0080 || loss_t_decoder3/batch : 1.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  54%|█████▍    | 19/35 [01:14<01:01,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4979 || loss_t_decoder2/batch : 1.4601 || loss_t_decoder3/batch : 1.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  57%|█████▋    | 20/35 [01:18<00:57,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8364 || loss_t_decoder2/batch : 0.8893 || loss_t_decoder3/batch : 1.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  60%|██████    | 21/35 [01:22<00:53,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8640 || loss_t_decoder2/batch : 0.9245 || loss_t_decoder3/batch : 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  63%|██████▎   | 22/35 [01:26<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4784 || loss_t_decoder2/batch : 1.4371 || loss_t_decoder3/batch : 1.4657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  66%|██████▌   | 23/35 [01:30<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0985 || loss_t_decoder2/batch : 1.0749 || loss_t_decoder3/batch : 1.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9205 || loss_t_decoder2/batch : 0.9633 || loss_t_decoder3/batch : 1.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7351 || loss_t_decoder2/batch : 0.8106 || loss_t_decoder3/batch : 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7659 || loss_t_decoder2/batch : 0.7935 || loss_t_decoder3/batch : 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  77%|███████▋  | 27/35 [01:45<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4947 || loss_t_decoder2/batch : 1.4826 || loss_t_decoder3/batch : 1.5728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  80%|████████  | 28/35 [01:49<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2626 || loss_t_decoder2/batch : 1.2861 || loss_t_decoder3/batch : 1.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9073 || loss_t_decoder2/batch : 0.9544 || loss_t_decoder3/batch : 1.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7169 || loss_t_decoder2/batch : 0.8213 || loss_t_decoder3/batch : 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  89%|████████▊ | 31/35 [02:00<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8301 || loss_t_decoder2/batch : 0.9282 || loss_t_decoder3/batch : 1.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  91%|█████████▏| 32/35 [02:04<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9741 || loss_t_decoder2/batch : 0.9849 || loss_t_decoder3/batch : 1.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2634 || loss_t_decoder2/batch : 1.2639 || loss_t_decoder3/batch : 1.3323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6882 || loss_t_decoder2/batch : 0.7817 || loss_t_decoder3/batch : 0.9408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 42/50): 100%|██████████| 35/35 [02:14<00:00,  3.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 42: 1.9119965996061052-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           42\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7505269646644592\n",
      "Cumulative loss: 0.7505269646644592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2463438510894775\n",
      "Cumulative loss: 1.996870756149292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1054191589355469\n",
      "Cumulative loss: 3.102289915084839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7498853802680969\n",
      "Cumulative loss: 3.852175235748291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0693994760513306\n",
      "Cumulative loss: 4.921574592590332\n",
      "------Final validation loss after epoch 42: 0.9843149185180664-------------\n",
      "Learning rate after epoch 42: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9712 || loss_t_decoder2/batch : 1.0054 || loss_t_decoder3/batch : 1.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):   3%|▎         | 1/35 [00:05<03:10,  5.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4286 || loss_t_decoder2/batch : 1.4654 || loss_t_decoder3/batch : 1.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):   6%|▌         | 2/35 [00:09<02:29,  4.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8355 || loss_t_decoder2/batch : 0.9158 || loss_t_decoder3/batch : 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):   9%|▊         | 3/35 [00:13<02:14,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2551 || loss_t_decoder2/batch : 1.3169 || loss_t_decoder3/batch : 1.3833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  11%|█▏        | 4/35 [00:16<02:04,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2905 || loss_t_decoder2/batch : 1.3493 || loss_t_decoder3/batch : 1.3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  14%|█▍        | 5/35 [00:20<01:58,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2160 || loss_t_decoder2/batch : 1.1906 || loss_t_decoder3/batch : 1.2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  17%|█▋        | 6/35 [00:24<01:52,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6385 || loss_t_decoder2/batch : 0.6714 || loss_t_decoder3/batch : 0.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  20%|██        | 7/35 [00:28<01:47,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6433 || loss_t_decoder2/batch : 0.7215 || loss_t_decoder3/batch : 0.7742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  23%|██▎       | 8/35 [00:32<01:43,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8926 || loss_t_decoder2/batch : 1.0208 || loss_t_decoder3/batch : 1.1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  26%|██▌       | 9/35 [00:35<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0886 || loss_t_decoder2/batch : 1.1658 || loss_t_decoder3/batch : 1.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  29%|██▊       | 10/35 [00:39<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2569 || loss_t_decoder2/batch : 1.2747 || loss_t_decoder3/batch : 1.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0567 || loss_t_decoder2/batch : 0.8855 || loss_t_decoder3/batch : 0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9968 || loss_t_decoder2/batch : 1.9154 || loss_t_decoder3/batch : 2.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6216 || loss_t_decoder2/batch : 0.7560 || loss_t_decoder3/batch : 0.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  40%|████      | 14/35 [00:54<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0506 || loss_t_decoder2/batch : 1.0737 || loss_t_decoder3/batch : 1.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9102 || loss_t_decoder2/batch : 0.9438 || loss_t_decoder3/batch : 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  46%|████▌     | 16/35 [01:02<01:12,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9186 || loss_t_decoder2/batch : 0.9377 || loss_t_decoder3/batch : 1.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2144 || loss_t_decoder2/batch : 1.2208 || loss_t_decoder3/batch : 1.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0353 || loss_t_decoder2/batch : 1.0586 || loss_t_decoder3/batch : 1.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5030 || loss_t_decoder2/batch : 1.4914 || loss_t_decoder3/batch : 1.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8634 || loss_t_decoder2/batch : 0.9226 || loss_t_decoder3/batch : 1.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8495 || loss_t_decoder2/batch : 0.9072 || loss_t_decoder3/batch : 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5120 || loss_t_decoder2/batch : 1.4299 || loss_t_decoder3/batch : 1.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0818 || loss_t_decoder2/batch : 1.0417 || loss_t_decoder3/batch : 1.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9399 || loss_t_decoder2/batch : 0.9604 || loss_t_decoder3/batch : 1.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8138 || loss_t_decoder2/batch : 0.8004 || loss_t_decoder3/batch : 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8493 || loss_t_decoder2/batch : 0.8028 || loss_t_decoder3/batch : 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4353 || loss_t_decoder2/batch : 1.4355 || loss_t_decoder3/batch : 1.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  80%|████████  | 28/35 [01:47<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2637 || loss_t_decoder2/batch : 1.2257 || loss_t_decoder3/batch : 1.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9329 || loss_t_decoder2/batch : 0.9080 || loss_t_decoder3/batch : 1.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7671 || loss_t_decoder2/batch : 0.8846 || loss_t_decoder3/batch : 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9168 || loss_t_decoder2/batch : 0.9319 || loss_t_decoder3/batch : 1.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9820 || loss_t_decoder2/batch : 1.0347 || loss_t_decoder3/batch : 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2640 || loss_t_decoder2/batch : 1.2777 || loss_t_decoder3/batch : 1.3381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7284 || loss_t_decoder2/batch : 0.8038 || loss_t_decoder3/batch : 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 43/50): 100%|██████████| 35/35 [02:13<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 43: 1.8902019841330393-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           43\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7046811580657959\n",
      "Cumulative loss: 0.7046811580657959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.298558235168457\n",
      "Cumulative loss: 2.003239393234253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0707592964172363\n",
      "Cumulative loss: 3.0739986896514893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.80619215965271\n",
      "Cumulative loss: 3.880190849304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1689770221710205\n",
      "Cumulative loss: 5.049167633056641\n",
      "------Final validation loss after epoch 43: 1.009833574295044-------------\n",
      "Learning rate after epoch 43: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0488 || loss_t_decoder2/batch : 1.0920 || loss_t_decoder3/batch : 1.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):   3%|▎         | 1/35 [00:05<03:09,  5.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4333 || loss_t_decoder2/batch : 1.4709 || loss_t_decoder3/batch : 1.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):   6%|▌         | 2/35 [00:09<02:29,  4.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8314 || loss_t_decoder2/batch : 0.8836 || loss_t_decoder3/batch : 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):   9%|▊         | 3/35 [00:13<02:14,  4.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4963 || loss_t_decoder2/batch : 1.5270 || loss_t_decoder3/batch : 1.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  11%|█▏        | 4/35 [00:16<02:05,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2480 || loss_t_decoder2/batch : 1.3091 || loss_t_decoder3/batch : 1.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  14%|█▍        | 5/35 [00:20<02:01,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2162 || loss_t_decoder2/batch : 1.2167 || loss_t_decoder3/batch : 1.2579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  17%|█▋        | 6/35 [00:24<01:54,  3.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6988 || loss_t_decoder2/batch : 0.7544 || loss_t_decoder3/batch : 0.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  20%|██        | 7/35 [00:28<01:49,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7054 || loss_t_decoder2/batch : 0.7830 || loss_t_decoder3/batch : 0.8353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  23%|██▎       | 8/35 [00:32<01:44,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0656 || loss_t_decoder2/batch : 1.1695 || loss_t_decoder3/batch : 1.2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2020 || loss_t_decoder2/batch : 1.3074 || loss_t_decoder3/batch : 1.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  29%|██▊       | 10/35 [00:39<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2807 || loss_t_decoder2/batch : 1.3094 || loss_t_decoder3/batch : 1.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9242 || loss_t_decoder2/batch : 0.9442 || loss_t_decoder3/batch : 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9791 || loss_t_decoder2/batch : 2.0277 || loss_t_decoder3/batch : 2.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  37%|███▋      | 13/35 [00:51<01:23,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6392 || loss_t_decoder2/batch : 0.7054 || loss_t_decoder3/batch : 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  40%|████      | 14/35 [00:55<01:19,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1451 || loss_t_decoder2/batch : 1.1742 || loss_t_decoder3/batch : 1.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  43%|████▎     | 15/35 [00:58<01:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8744 || loss_t_decoder2/batch : 0.9576 || loss_t_decoder3/batch : 1.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0421 || loss_t_decoder2/batch : 0.9650 || loss_t_decoder3/batch : 1.1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3400 || loss_t_decoder2/batch : 1.2984 || loss_t_decoder3/batch : 1.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1027 || loss_t_decoder2/batch : 1.1668 || loss_t_decoder3/batch : 1.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4327 || loss_t_decoder2/batch : 1.4677 || loss_t_decoder3/batch : 1.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8203 || loss_t_decoder2/batch : 0.8907 || loss_t_decoder3/batch : 1.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8568 || loss_t_decoder2/batch : 0.9682 || loss_t_decoder3/batch : 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5511 || loss_t_decoder2/batch : 1.4681 || loss_t_decoder3/batch : 1.5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2937 || loss_t_decoder2/batch : 1.1853 || loss_t_decoder3/batch : 1.3412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9276 || loss_t_decoder2/batch : 0.9494 || loss_t_decoder3/batch : 1.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8111 || loss_t_decoder2/batch : 0.8137 || loss_t_decoder3/batch : 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8709 || loss_t_decoder2/batch : 0.8685 || loss_t_decoder3/batch : 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5008 || loss_t_decoder2/batch : 1.4562 || loss_t_decoder3/batch : 1.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2542 || loss_t_decoder2/batch : 1.3066 || loss_t_decoder3/batch : 1.3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9526 || loss_t_decoder2/batch : 1.0178 || loss_t_decoder3/batch : 1.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7613 || loss_t_decoder2/batch : 0.7921 || loss_t_decoder3/batch : 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0004 || loss_t_decoder2/batch : 1.0232 || loss_t_decoder3/batch : 1.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9684 || loss_t_decoder2/batch : 0.9169 || loss_t_decoder3/batch : 1.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2431 || loss_t_decoder2/batch : 1.3142 || loss_t_decoder3/batch : 1.3433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7463 || loss_t_decoder2/batch : 0.8084 || loss_t_decoder3/batch : 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 44/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 44: 1.955043717793056-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           44\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7897955179214478\n",
      "Cumulative loss: 0.7897955179214478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2656044960021973\n",
      "Cumulative loss: 2.0553998947143555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1112391948699951\n",
      "Cumulative loss: 3.1666390895843506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8391110301017761\n",
      "Cumulative loss: 4.0057501792907715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.201960802078247\n",
      "Cumulative loss: 5.207711219787598\n",
      "------Final validation loss after epoch 44: 1.0415422916412354-------------\n",
      "Learning rate after epoch 44: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0115 || loss_t_decoder2/batch : 1.0789 || loss_t_decoder3/batch : 1.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):   3%|▎         | 1/35 [00:05<03:14,  5.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4654 || loss_t_decoder2/batch : 1.5250 || loss_t_decoder3/batch : 1.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):   6%|▌         | 2/35 [00:09<02:30,  4.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8407 || loss_t_decoder2/batch : 0.8993 || loss_t_decoder3/batch : 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):   9%|▊         | 3/35 [00:13<02:15,  4.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4253 || loss_t_decoder2/batch : 1.5042 || loss_t_decoder3/batch : 1.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  11%|█▏        | 4/35 [00:17<02:05,  4.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2418 || loss_t_decoder2/batch : 1.2966 || loss_t_decoder3/batch : 1.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  14%|█▍        | 5/35 [00:20<01:58,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2228 || loss_t_decoder2/batch : 1.2719 || loss_t_decoder3/batch : 1.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  17%|█▋        | 6/35 [00:24<01:53,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7440 || loss_t_decoder2/batch : 0.7513 || loss_t_decoder3/batch : 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  20%|██        | 7/35 [00:28<01:48,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7169 || loss_t_decoder2/batch : 0.7703 || loss_t_decoder3/batch : 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  23%|██▎       | 8/35 [00:32<01:43,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0043 || loss_t_decoder2/batch : 1.0944 || loss_t_decoder3/batch : 1.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3156 || loss_t_decoder2/batch : 1.3994 || loss_t_decoder3/batch : 1.3970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  29%|██▊       | 10/35 [00:39<01:35,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2644 || loss_t_decoder2/batch : 1.2905 || loss_t_decoder3/batch : 1.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  31%|███▏      | 11/35 [00:43<01:33,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9238 || loss_t_decoder2/batch : 0.8927 || loss_t_decoder3/batch : 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  34%|███▍      | 12/35 [00:47<01:28,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9967 || loss_t_decoder2/batch : 2.0137 || loss_t_decoder3/batch : 2.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  37%|███▋      | 13/35 [00:51<01:24,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6304 || loss_t_decoder2/batch : 0.7436 || loss_t_decoder3/batch : 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  40%|████      | 14/35 [00:55<01:20,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1269 || loss_t_decoder2/batch : 1.2389 || loss_t_decoder3/batch : 1.3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  43%|████▎     | 15/35 [00:59<01:16,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8682 || loss_t_decoder2/batch : 0.9423 || loss_t_decoder3/batch : 1.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9896 || loss_t_decoder2/batch : 0.9531 || loss_t_decoder3/batch : 1.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1012 || loss_t_decoder2/batch : 1.0440 || loss_t_decoder3/batch : 1.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0941 || loss_t_decoder2/batch : 1.1012 || loss_t_decoder3/batch : 1.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5537 || loss_t_decoder2/batch : 1.5504 || loss_t_decoder3/batch : 1.5531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8269 || loss_t_decoder2/batch : 0.8866 || loss_t_decoder3/batch : 1.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  60%|██████    | 21/35 [01:21<00:53,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8120 || loss_t_decoder2/batch : 0.8955 || loss_t_decoder3/batch : 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4675 || loss_t_decoder2/batch : 1.4702 || loss_t_decoder3/batch : 1.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0795 || loss_t_decoder2/batch : 1.0995 || loss_t_decoder3/batch : 1.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9606 || loss_t_decoder2/batch : 0.9880 || loss_t_decoder3/batch : 1.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8400 || loss_t_decoder2/batch : 0.8786 || loss_t_decoder3/batch : 0.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8665 || loss_t_decoder2/batch : 0.9008 || loss_t_decoder3/batch : 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5129 || loss_t_decoder2/batch : 1.4893 || loss_t_decoder3/batch : 1.5713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  80%|████████  | 28/35 [01:48<00:26,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3039 || loss_t_decoder2/batch : 1.3257 || loss_t_decoder3/batch : 1.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9709 || loss_t_decoder2/batch : 1.0149 || loss_t_decoder3/batch : 1.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6426 || loss_t_decoder2/batch : 0.7047 || loss_t_decoder3/batch : 0.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8340 || loss_t_decoder2/batch : 0.8676 || loss_t_decoder3/batch : 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8463 || loss_t_decoder2/batch : 0.8429 || loss_t_decoder3/batch : 0.9409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2417 || loss_t_decoder2/batch : 1.2620 || loss_t_decoder3/batch : 1.3063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7149 || loss_t_decoder2/batch : 0.7515 || loss_t_decoder3/batch : 0.8728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 45/50): 100%|██████████| 35/35 [02:13<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 45: 1.9184928621564592-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           45\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8489011526107788\n",
      "Cumulative loss: 0.8489011526107788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2895455360412598\n",
      "Cumulative loss: 2.138446807861328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1157612800598145\n",
      "Cumulative loss: 3.2542080879211426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.852977991104126\n",
      "Cumulative loss: 4.107186317443848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0459587574005127\n",
      "Cumulative loss: 5.153144836425781\n",
      "------Final validation loss after epoch 45: 1.03062903881073-------------\n",
      "Learning rate after epoch 45: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9917 || loss_t_decoder2/batch : 0.9959 || loss_t_decoder3/batch : 1.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):   3%|▎         | 1/35 [00:05<03:22,  5.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4402 || loss_t_decoder2/batch : 1.4619 || loss_t_decoder3/batch : 1.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):   6%|▌         | 2/35 [00:09<02:34,  4.68s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8888 || loss_t_decoder2/batch : 0.9546 || loss_t_decoder3/batch : 1.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):   9%|▊         | 3/35 [00:13<02:17,  4.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3953 || loss_t_decoder2/batch : 1.4340 || loss_t_decoder3/batch : 1.4114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  11%|█▏        | 4/35 [00:17<02:06,  4.09s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2349 || loss_t_decoder2/batch : 1.2691 || loss_t_decoder3/batch : 1.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  14%|█▍        | 5/35 [00:21<02:01,  4.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2414 || loss_t_decoder2/batch : 1.2769 || loss_t_decoder3/batch : 1.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  17%|█▋        | 6/35 [00:25<01:54,  3.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6239 || loss_t_decoder2/batch : 0.6460 || loss_t_decoder3/batch : 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  20%|██        | 7/35 [00:28<01:49,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6967 || loss_t_decoder2/batch : 0.7330 || loss_t_decoder3/batch : 0.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  23%|██▎       | 8/35 [00:32<01:44,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9537 || loss_t_decoder2/batch : 1.0363 || loss_t_decoder3/batch : 1.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  26%|██▌       | 9/35 [00:36<01:39,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1283 || loss_t_decoder2/batch : 1.1710 || loss_t_decoder3/batch : 1.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2623 || loss_t_decoder2/batch : 1.2909 || loss_t_decoder3/batch : 1.4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  31%|███▏      | 11/35 [00:44<01:31,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9787 || loss_t_decoder2/batch : 0.9805 || loss_t_decoder3/batch : 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  34%|███▍      | 12/35 [00:47<01:27,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.8936 || loss_t_decoder2/batch : 1.8711 || loss_t_decoder3/batch : 2.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  37%|███▋      | 13/35 [00:51<01:23,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6696 || loss_t_decoder2/batch : 0.7470 || loss_t_decoder3/batch : 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  40%|████      | 14/35 [00:55<01:19,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9994 || loss_t_decoder2/batch : 1.1017 || loss_t_decoder3/batch : 1.2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  43%|████▎     | 15/35 [00:59<01:15,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8293 || loss_t_decoder2/batch : 0.9175 || loss_t_decoder3/batch : 0.9978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  46%|████▌     | 16/35 [01:03<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9997 || loss_t_decoder2/batch : 0.9374 || loss_t_decoder3/batch : 1.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2652 || loss_t_decoder2/batch : 1.2018 || loss_t_decoder3/batch : 1.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1876 || loss_t_decoder2/batch : 1.1842 || loss_t_decoder3/batch : 1.2766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4545 || loss_t_decoder2/batch : 1.4508 || loss_t_decoder3/batch : 1.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8212 || loss_t_decoder2/batch : 0.8958 || loss_t_decoder3/batch : 1.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  60%|██████    | 21/35 [01:22<00:53,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8365 || loss_t_decoder2/batch : 0.8873 || loss_t_decoder3/batch : 1.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5518 || loss_t_decoder2/batch : 1.4964 || loss_t_decoder3/batch : 1.5453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2631 || loss_t_decoder2/batch : 1.1938 || loss_t_decoder3/batch : 1.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9609 || loss_t_decoder2/batch : 0.9533 || loss_t_decoder3/batch : 1.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8518 || loss_t_decoder2/batch : 0.8384 || loss_t_decoder3/batch : 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8659 || loss_t_decoder2/batch : 0.8551 || loss_t_decoder3/batch : 0.9047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.5950 || loss_t_decoder2/batch : 1.5356 || loss_t_decoder3/batch : 1.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3501 || loss_t_decoder2/batch : 1.3423 || loss_t_decoder3/batch : 1.4434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9192 || loss_t_decoder2/batch : 0.9594 || loss_t_decoder3/batch : 1.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6800 || loss_t_decoder2/batch : 0.7322 || loss_t_decoder3/batch : 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7531 || loss_t_decoder2/batch : 0.7985 || loss_t_decoder3/batch : 0.9697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9354 || loss_t_decoder2/batch : 0.9335 || loss_t_decoder3/batch : 1.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2705 || loss_t_decoder2/batch : 1.2617 || loss_t_decoder3/batch : 1.3286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7216 || loss_t_decoder2/batch : 0.7693 || loss_t_decoder3/batch : 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 46/50): 100%|██████████| 35/35 [02:13<00:00,  3.82s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 46: 1.911015398161752-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           46\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7487627267837524\n",
      "Cumulative loss: 0.7487627267837524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.236446499824524\n",
      "Cumulative loss: 1.9852092266082764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1196346282958984\n",
      "Cumulative loss: 3.104843854904175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0173349380493164\n",
      "Cumulative loss: 4.12217903137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0864157676696777\n",
      "Cumulative loss: 5.208594799041748\n",
      "------Final validation loss after epoch 46: 1.0417189598083496-------------\n",
      "Learning rate after epoch 46: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9716 || loss_t_decoder2/batch : 0.9898 || loss_t_decoder3/batch : 1.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):   3%|▎         | 1/35 [00:05<03:10,  5.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4192 || loss_t_decoder2/batch : 1.4631 || loss_t_decoder3/batch : 1.4741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):   6%|▌         | 2/35 [00:09<02:41,  4.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8291 || loss_t_decoder2/batch : 0.8690 || loss_t_decoder3/batch : 0.9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):   9%|▊         | 3/35 [00:13<02:20,  4.38s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4293 || loss_t_decoder2/batch : 1.4708 || loss_t_decoder3/batch : 1.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  11%|█▏        | 4/35 [00:17<02:08,  4.15s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2398 || loss_t_decoder2/batch : 1.2762 || loss_t_decoder3/batch : 1.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  14%|█▍        | 5/35 [00:21<02:00,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2236 || loss_t_decoder2/batch : 1.2343 || loss_t_decoder3/batch : 1.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  17%|█▋        | 6/35 [00:25<01:54,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6533 || loss_t_decoder2/batch : 0.7085 || loss_t_decoder3/batch : 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  20%|██        | 7/35 [00:29<01:49,  3.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6472 || loss_t_decoder2/batch : 0.6817 || loss_t_decoder3/batch : 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  23%|██▎       | 8/35 [00:32<01:44,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9255 || loss_t_decoder2/batch : 0.9822 || loss_t_decoder3/batch : 1.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  26%|██▌       | 9/35 [00:36<01:40,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0480 || loss_t_decoder2/batch : 1.0744 || loss_t_decoder3/batch : 1.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  29%|██▊       | 10/35 [00:41<01:40,  4.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2643 || loss_t_decoder2/batch : 1.2904 || loss_t_decoder3/batch : 1.3697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  31%|███▏      | 11/35 [00:44<01:34,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9833 || loss_t_decoder2/batch : 0.8652 || loss_t_decoder3/batch : 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  34%|███▍      | 12/35 [00:48<01:29,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 2.0057 || loss_t_decoder2/batch : 2.0477 || loss_t_decoder3/batch : 2.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  37%|███▋      | 13/35 [00:52<01:25,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6559 || loss_t_decoder2/batch : 0.7795 || loss_t_decoder3/batch : 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  40%|████      | 14/35 [00:56<01:20,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1555 || loss_t_decoder2/batch : 1.1404 || loss_t_decoder3/batch : 1.3018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  43%|████▎     | 15/35 [00:59<01:16,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8499 || loss_t_decoder2/batch : 0.9263 || loss_t_decoder3/batch : 1.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  46%|████▌     | 16/35 [01:03<01:12,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9547 || loss_t_decoder2/batch : 1.0092 || loss_t_decoder3/batch : 1.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  49%|████▊     | 17/35 [01:07<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0233 || loss_t_decoder2/batch : 1.0480 || loss_t_decoder3/batch : 1.2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  51%|█████▏    | 18/35 [01:11<01:04,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9644 || loss_t_decoder2/batch : 0.9835 || loss_t_decoder3/batch : 1.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  54%|█████▍    | 19/35 [01:15<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4288 || loss_t_decoder2/batch : 1.4393 || loss_t_decoder3/batch : 1.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8097 || loss_t_decoder2/batch : 0.8986 || loss_t_decoder3/batch : 1.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  60%|██████    | 21/35 [01:22<00:53,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8228 || loss_t_decoder2/batch : 0.8936 || loss_t_decoder3/batch : 1.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  63%|██████▎   | 22/35 [01:26<00:49,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4020 || loss_t_decoder2/batch : 1.4200 || loss_t_decoder3/batch : 1.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  66%|██████▌   | 23/35 [01:30<00:45,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9736 || loss_t_decoder2/batch : 1.0358 || loss_t_decoder3/batch : 1.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  69%|██████▊   | 24/35 [01:34<00:41,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8965 || loss_t_decoder2/batch : 0.9419 || loss_t_decoder3/batch : 1.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7557 || loss_t_decoder2/batch : 0.8159 || loss_t_decoder3/batch : 1.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  74%|███████▍  | 26/35 [01:41<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7992 || loss_t_decoder2/batch : 0.8254 || loss_t_decoder3/batch : 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  77%|███████▋  | 27/35 [01:45<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4191 || loss_t_decoder2/batch : 1.4818 || loss_t_decoder3/batch : 1.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  80%|████████  | 28/35 [01:49<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2416 || loss_t_decoder2/batch : 1.2717 || loss_t_decoder3/batch : 1.3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  83%|████████▎ | 29/35 [01:53<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8967 || loss_t_decoder2/batch : 0.9704 || loss_t_decoder3/batch : 1.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6493 || loss_t_decoder2/batch : 0.7040 || loss_t_decoder3/batch : 0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  89%|████████▊ | 31/35 [02:00<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6992 || loss_t_decoder2/batch : 0.7775 || loss_t_decoder3/batch : 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  91%|█████████▏| 32/35 [02:04<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9123 || loss_t_decoder2/batch : 0.8690 || loss_t_decoder3/batch : 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  94%|█████████▍| 33/35 [02:08<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3061 || loss_t_decoder2/batch : 1.2865 || loss_t_decoder3/batch : 1.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7319 || loss_t_decoder2/batch : 0.7955 || loss_t_decoder3/batch : 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 47/50): 100%|██████████| 35/35 [02:14<00:00,  3.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 47: 1.8506171601159231-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           47\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6503694653511047\n",
      "Cumulative loss: 0.6503694653511047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2965338230133057\n",
      "Cumulative loss: 1.9469032287597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1351709365844727\n",
      "Cumulative loss: 3.0820741653442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7736897468566895\n",
      "Cumulative loss: 3.8557639122009277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1077404022216797\n",
      "Cumulative loss: 4.963504314422607\n",
      "------Final validation loss after epoch 47: 0.9927008748054504-------------\n",
      "Learning rate after epoch 47: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9945 || loss_t_decoder2/batch : 1.0361 || loss_t_decoder3/batch : 1.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):   3%|▎         | 1/35 [00:05<03:14,  5.72s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3781 || loss_t_decoder2/batch : 1.4243 || loss_t_decoder3/batch : 1.5695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):   6%|▌         | 2/35 [00:09<02:31,  4.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7737 || loss_t_decoder2/batch : 0.8549 || loss_t_decoder3/batch : 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):   9%|▊         | 3/35 [00:13<02:14,  4.21s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3299 || loss_t_decoder2/batch : 1.4190 || loss_t_decoder3/batch : 1.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  11%|█▏        | 4/35 [00:17<02:05,  4.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2272 || loss_t_decoder2/batch : 1.2678 || loss_t_decoder3/batch : 1.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  14%|█▍        | 5/35 [00:20<01:58,  3.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2780 || loss_t_decoder2/batch : 1.2448 || loss_t_decoder3/batch : 1.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  17%|█▋        | 6/35 [00:24<01:53,  3.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7654 || loss_t_decoder2/batch : 0.7309 || loss_t_decoder3/batch : 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  20%|██        | 7/35 [00:28<01:48,  3.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6307 || loss_t_decoder2/batch : 0.6575 || loss_t_decoder3/batch : 0.7359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  23%|██▎       | 8/35 [00:32<01:43,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8177 || loss_t_decoder2/batch : 0.9470 || loss_t_decoder3/batch : 1.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0293 || loss_t_decoder2/batch : 1.0813 || loss_t_decoder3/batch : 1.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  29%|██▊       | 10/35 [00:39<01:35,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2719 || loss_t_decoder2/batch : 1.2958 || loss_t_decoder3/batch : 1.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  31%|███▏      | 11/35 [00:43<01:33,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9165 || loss_t_decoder2/batch : 0.8991 || loss_t_decoder3/batch : 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  34%|███▍      | 12/35 [00:47<01:28,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9314 || loss_t_decoder2/batch : 1.9571 || loss_t_decoder3/batch : 2.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  37%|███▋      | 13/35 [00:51<01:24,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6416 || loss_t_decoder2/batch : 0.7235 || loss_t_decoder3/batch : 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  40%|████      | 14/35 [00:55<01:20,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9508 || loss_t_decoder2/batch : 1.0200 || loss_t_decoder3/batch : 1.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  43%|████▎     | 15/35 [00:58<01:16,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8987 || loss_t_decoder2/batch : 0.9641 || loss_t_decoder3/batch : 1.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9442 || loss_t_decoder2/batch : 0.9540 || loss_t_decoder3/batch : 1.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9827 || loss_t_decoder2/batch : 1.0346 || loss_t_decoder3/batch : 1.2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9724 || loss_t_decoder2/batch : 1.0207 || loss_t_decoder3/batch : 1.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3608 || loss_t_decoder2/batch : 1.4299 || loss_t_decoder3/batch : 1.4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7714 || loss_t_decoder2/batch : 0.9051 || loss_t_decoder3/batch : 1.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  60%|██████    | 21/35 [01:21<00:52,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8263 || loss_t_decoder2/batch : 0.9079 || loss_t_decoder3/batch : 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4019 || loss_t_decoder2/batch : 1.3643 || loss_t_decoder3/batch : 1.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9798 || loss_t_decoder2/batch : 1.0087 || loss_t_decoder3/batch : 1.1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8921 || loss_t_decoder2/batch : 0.9382 || loss_t_decoder3/batch : 1.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6577 || loss_t_decoder2/batch : 0.7555 || loss_t_decoder3/batch : 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  74%|███████▍  | 26/35 [01:40<00:33,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7023 || loss_t_decoder2/batch : 0.7530 || loss_t_decoder3/batch : 0.9010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4109 || loss_t_decoder2/batch : 1.4501 || loss_t_decoder3/batch : 1.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  80%|████████  | 28/35 [01:48<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3703 || loss_t_decoder2/batch : 1.2840 || loss_t_decoder3/batch : 1.3418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7546 || loss_t_decoder2/batch : 0.8994 || loss_t_decoder3/batch : 0.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6902 || loss_t_decoder2/batch : 0.7164 || loss_t_decoder3/batch : 0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7553 || loss_t_decoder2/batch : 0.7626 || loss_t_decoder3/batch : 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6944 || loss_t_decoder2/batch : 0.7604 || loss_t_decoder3/batch : 0.8402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2277 || loss_t_decoder2/batch : 1.2618 || loss_t_decoder3/batch : 1.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7028 || loss_t_decoder2/batch : 0.8405 || loss_t_decoder3/batch : 0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 48/50): 100%|██████████| 35/35 [02:13<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 48: 1.807219706262861-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           48\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:02<00:11,  2.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.6561729907989502\n",
      "Cumulative loss: 0.6561729907989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:03<00:05,  1.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.3724651336669922\n",
      "Cumulative loss: 2.0286381244659424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:04<00:02,  1.42s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2318837642669678\n",
      "Cumulative loss: 3.26052188873291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:05<00:01,  1.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7764171361923218\n",
      "Cumulative loss: 4.0369391441345215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.0347987413406372\n",
      "Cumulative loss: 5.071737766265869\n",
      "------Final validation loss after epoch 48: 1.0143475532531738-------------\n",
      "Learning rate after epoch 48: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9677 || loss_t_decoder2/batch : 1.0323 || loss_t_decoder3/batch : 1.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):   3%|▎         | 1/35 [00:05<03:06,  5.50s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.4181 || loss_t_decoder2/batch : 1.4928 || loss_t_decoder3/batch : 1.5178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):   6%|▌         | 2/35 [00:09<02:28,  4.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7404 || loss_t_decoder2/batch : 0.8894 || loss_t_decoder3/batch : 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):   9%|▊         | 3/35 [00:13<02:13,  4.16s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1854 || loss_t_decoder2/batch : 1.3044 || loss_t_decoder3/batch : 1.3531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  11%|█▏        | 4/35 [00:16<02:04,  4.02s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2219 || loss_t_decoder2/batch : 1.2780 || loss_t_decoder3/batch : 1.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  14%|█▍        | 5/35 [00:20<01:59,  3.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2897 || loss_t_decoder2/batch : 1.1699 || loss_t_decoder3/batch : 1.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  17%|█▋        | 6/35 [00:24<01:53,  3.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7019 || loss_t_decoder2/batch : 0.6902 || loss_t_decoder3/batch : 0.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  20%|██        | 7/35 [00:28<01:48,  3.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5138 || loss_t_decoder2/batch : 0.6513 || loss_t_decoder3/batch : 0.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  23%|██▎       | 8/35 [00:32<01:43,  3.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7318 || loss_t_decoder2/batch : 0.9027 || loss_t_decoder3/batch : 1.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  26%|██▌       | 9/35 [00:35<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0590 || loss_t_decoder2/batch : 1.1167 || loss_t_decoder3/batch : 1.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  29%|██▊       | 10/35 [00:39<01:35,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2653 || loss_t_decoder2/batch : 1.2755 || loss_t_decoder3/batch : 1.3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  31%|███▏      | 11/35 [00:43<01:31,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9091 || loss_t_decoder2/batch : 0.8870 || loss_t_decoder3/batch : 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  34%|███▍      | 12/35 [00:47<01:27,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9105 || loss_t_decoder2/batch : 1.9196 || loss_t_decoder3/batch : 1.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  37%|███▋      | 13/35 [00:51<01:23,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6325 || loss_t_decoder2/batch : 0.7247 || loss_t_decoder3/batch : 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  40%|████      | 14/35 [00:54<01:19,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9367 || loss_t_decoder2/batch : 1.0013 || loss_t_decoder3/batch : 1.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  43%|████▎     | 15/35 [00:58<01:16,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9865 || loss_t_decoder2/batch : 0.9238 || loss_t_decoder3/batch : 1.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  46%|████▌     | 16/35 [01:02<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9870 || loss_t_decoder2/batch : 1.1715 || loss_t_decoder3/batch : 1.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  49%|████▊     | 17/35 [01:06<01:08,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9240 || loss_t_decoder2/batch : 1.0583 || loss_t_decoder3/batch : 1.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9287 || loss_t_decoder2/batch : 0.9578 || loss_t_decoder3/batch : 1.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  54%|█████▍    | 19/35 [01:13<01:00,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2222 || loss_t_decoder2/batch : 1.3559 || loss_t_decoder3/batch : 1.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  57%|█████▋    | 20/35 [01:17<00:56,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8156 || loss_t_decoder2/batch : 0.8533 || loss_t_decoder3/batch : 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  60%|██████    | 21/35 [01:21<00:52,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8109 || loss_t_decoder2/batch : 0.8681 || loss_t_decoder3/batch : 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3336 || loss_t_decoder2/batch : 1.3558 || loss_t_decoder3/batch : 1.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  66%|██████▌   | 23/35 [01:28<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9889 || loss_t_decoder2/batch : 1.0324 || loss_t_decoder3/batch : 1.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  69%|██████▊   | 24/35 [01:32<00:41,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8857 || loss_t_decoder2/batch : 0.9475 || loss_t_decoder3/batch : 1.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  71%|███████▏  | 25/35 [01:36<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6624 || loss_t_decoder2/batch : 0.8406 || loss_t_decoder3/batch : 1.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5783 || loss_t_decoder2/batch : 0.8584 || loss_t_decoder3/batch : 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3891 || loss_t_decoder2/batch : 1.4487 || loss_t_decoder3/batch : 1.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  80%|████████  | 28/35 [01:47<00:26,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2501 || loss_t_decoder2/batch : 1.2673 || loss_t_decoder3/batch : 1.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  83%|████████▎ | 29/35 [01:51<00:22,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5930 || loss_t_decoder2/batch : 0.9058 || loss_t_decoder3/batch : 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  86%|████████▌ | 30/35 [01:55<00:18,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6895 || loss_t_decoder2/batch : 0.6825 || loss_t_decoder3/batch : 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6154 || loss_t_decoder2/batch : 0.6976 || loss_t_decoder3/batch : 0.8376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6002 || loss_t_decoder2/batch : 0.7730 || loss_t_decoder3/batch : 0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  94%|█████████▍| 33/35 [02:06<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2323 || loss_t_decoder2/batch : 1.2479 || loss_t_decoder3/batch : 1.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50):  97%|█████████▋| 34/35 [02:10<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6903 || loss_t_decoder2/batch : 0.8720 || loss_t_decoder3/batch : 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 49/50): 100%|██████████| 35/35 [02:12<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 49: 1.7658936057771955-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           49\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:03<00:12,  3.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7724497318267822\n",
      "Cumulative loss: 0.7724497318267822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1362571716308594\n",
      "Cumulative loss: 1.9087069034576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.2377346754074097\n",
      "Cumulative loss: 3.1464414596557617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8269375562667847\n",
      "Cumulative loss: 3.973379135131836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.9926183223724365\n",
      "Cumulative loss: 4.965997695922852\n",
      "------Final validation loss after epoch 49: 0.9931995272636414-------------\n",
      "Learning rate after epoch 49: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):   0%|          | 0/35 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9475 || loss_t_decoder2/batch : 1.0421 || loss_t_decoder3/batch : 1.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):   3%|▎         | 1/35 [00:06<03:24,  6.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2243 || loss_t_decoder2/batch : 1.4419 || loss_t_decoder3/batch : 1.4938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):   6%|▌         | 2/35 [00:09<02:34,  4.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6534 || loss_t_decoder2/batch : 0.8832 || loss_t_decoder3/batch : 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):   9%|▊         | 3/35 [00:13<02:16,  4.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1859 || loss_t_decoder2/batch : 1.3171 || loss_t_decoder3/batch : 1.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  11%|█▏        | 4/35 [00:17<02:06,  4.09s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2208 || loss_t_decoder2/batch : 1.2964 || loss_t_decoder3/batch : 1.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  14%|█▍        | 5/35 [00:21<02:00,  4.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0666 || loss_t_decoder2/batch : 1.2029 || loss_t_decoder3/batch : 1.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  17%|█▋        | 6/35 [00:25<01:54,  3.94s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6479 || loss_t_decoder2/batch : 0.7035 || loss_t_decoder3/batch : 0.8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  20%|██        | 7/35 [00:28<01:48,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5844 || loss_t_decoder2/batch : 0.7121 || loss_t_decoder3/batch : 0.7841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  23%|██▎       | 8/35 [00:32<01:44,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9779 || loss_t_decoder2/batch : 1.1546 || loss_t_decoder3/batch : 1.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  26%|██▌       | 9/35 [00:36<01:39,  3.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8650 || loss_t_decoder2/batch : 1.1850 || loss_t_decoder3/batch : 1.2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  29%|██▊       | 10/35 [00:40<01:35,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2609 || loss_t_decoder2/batch : 1.2829 || loss_t_decoder3/batch : 1.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  31%|███▏      | 11/35 [00:44<01:32,  3.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0213 || loss_t_decoder2/batch : 0.9053 || loss_t_decoder3/batch : 0.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  34%|███▍      | 12/35 [00:47<01:28,  3.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.9880 || loss_t_decoder2/batch : 1.8839 || loss_t_decoder3/batch : 1.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  37%|███▋      | 13/35 [00:51<01:24,  3.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6284 || loss_t_decoder2/batch : 0.7064 || loss_t_decoder3/batch : 0.8263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  40%|████      | 14/35 [00:55<01:19,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2827 || loss_t_decoder2/batch : 1.1512 || loss_t_decoder3/batch : 1.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  43%|████▎     | 15/35 [00:59<01:16,  3.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8613 || loss_t_decoder2/batch : 1.0471 || loss_t_decoder3/batch : 1.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  46%|████▌     | 16/35 [01:03<01:12,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0306 || loss_t_decoder2/batch : 0.9550 || loss_t_decoder3/batch : 1.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  49%|████▊     | 17/35 [01:06<01:08,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.7384 || loss_t_decoder2/batch : 0.9099 || loss_t_decoder3/batch : 1.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  51%|█████▏    | 18/35 [01:10<01:04,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8282 || loss_t_decoder2/batch : 0.8977 || loss_t_decoder3/batch : 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  54%|█████▍    | 19/35 [01:14<01:00,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.0898 || loss_t_decoder2/batch : 1.3377 || loss_t_decoder3/batch : 1.3978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  57%|█████▋    | 20/35 [01:18<00:56,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.9096 || loss_t_decoder2/batch : 0.8475 || loss_t_decoder3/batch : 1.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  60%|██████    | 21/35 [01:22<00:53,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8039 || loss_t_decoder2/batch : 0.8878 || loss_t_decoder3/batch : 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  63%|██████▎   | 22/35 [01:25<00:49,  3.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.2939 || loss_t_decoder2/batch : 1.3577 || loss_t_decoder3/batch : 1.4020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  66%|██████▌   | 23/35 [01:29<00:45,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8403 || loss_t_decoder2/batch : 1.0028 || loss_t_decoder3/batch : 1.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  69%|██████▊   | 24/35 [01:33<00:41,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.8611 || loss_t_decoder2/batch : 0.9551 || loss_t_decoder3/batch : 1.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  71%|███████▏  | 25/35 [01:37<00:37,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5992 || loss_t_decoder2/batch : 0.7371 || loss_t_decoder3/batch : 0.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  74%|███████▍  | 26/35 [01:40<00:34,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.4977 || loss_t_decoder2/batch : 0.7774 || loss_t_decoder3/batch : 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  77%|███████▋  | 27/35 [01:44<00:30,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.3256 || loss_t_decoder2/batch : 1.3786 || loss_t_decoder3/batch : 1.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  80%|████████  | 28/35 [01:48<00:26,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1318 || loss_t_decoder2/batch : 1.2049 || loss_t_decoder3/batch : 1.2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  83%|████████▎ | 29/35 [01:52<00:22,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5683 || loss_t_decoder2/batch : 0.8879 || loss_t_decoder3/batch : 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  86%|████████▌ | 30/35 [01:56<00:18,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6012 || loss_t_decoder2/batch : 0.6931 || loss_t_decoder3/batch : 0.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  89%|████████▊ | 31/35 [01:59<00:15,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6068 || loss_t_decoder2/batch : 0.7108 || loss_t_decoder3/batch : 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  91%|█████████▏| 32/35 [02:03<00:11,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.6225 || loss_t_decoder2/batch : 0.8473 || loss_t_decoder3/batch : 0.8767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  94%|█████████▍| 33/35 [02:07<00:07,  3.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 1.1938 || loss_t_decoder2/batch : 1.2375 || loss_t_decoder3/batch : 1.3094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50):  97%|█████████▋| 34/35 [02:11<00:03,  3.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_t_decoder1/batch : 0.5786 || loss_t_decoder2/batch : 0.7254 || loss_t_decoder3/batch : 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 50/50): 100%|██████████| 35/35 [02:13<00:00,  3.82s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Final training loss after epoch 50: 1.728943463734218-------------\n",
      "\n",
      "            Starting validation:\n",
      "            Epoch:           50\n",
      "            Batch size:      2\n",
      "            Validation data coming from: /kaggle/input/bratsped/Training\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/5 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "Validating:  20%|██        | 1/5 [00:03<00:12,  3.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.7537146806716919\n",
      "Cumulative loss: 0.7537146806716919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  40%|████      | 2/5 [00:04<00:05,  1.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1317583322525024\n",
      "Cumulative loss: 1.8854730129241943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  60%|██████    | 3/5 [00:05<00:02,  1.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 1.1935937404632568\n",
      "Cumulative loss: 3.079066753387451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  80%|████████  | 4/5 [00:06<00:01,  1.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.991579532623291\n",
      "Cumulative loss: 4.070646286010742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per batch: 0.8866398334503174\n",
      "Cumulative loss: 4.9572858810424805\n",
      "------Final validation loss after epoch 50: 0.9914571642875671-------------\n",
      "Learning rate after epoch 50: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after epoch 50\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'workers': 2,\n",
    "    'epochs': 25,\n",
    "    'train_batch_size': 2,\n",
    "    'val_batch_size': 2,\n",
    "    'test_batch_size': 3,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'data_dir': '/kaggle/input/bratsped/Training',\n",
    "    'in_checkpoint_dir': Path('/kaggle/input/ped-hybrid'),\n",
    "    'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "}\n",
    "trainLoader, valLoader, testLoader = prepare_data_loaders(args)\n",
    "run_model(trainLoader, valLoader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e52e528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T18:34:41.245377Z",
     "iopub.status.busy": "2026-01-23T18:34:41.244097Z",
     "iopub.status.idle": "2026-01-23T18:34:41.249445Z",
     "shell.execute_reply": "2026-01-23T18:34:41.248549Z"
    },
    "papermill": {
     "duration": 0.115901,
     "end_time": "2026-01-23T18:34:41.251217",
     "exception": false,
     "start_time": "2026-01-23T18:34:41.135316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # For freeing gpu\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d6ffb",
   "metadata": {
    "papermill": {
     "duration": 0.102381,
     "end_time": "2026-01-23T18:34:41.455604",
     "exception": false,
     "start_time": "2026-01-23T18:34:41.353223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58cc552f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T18:34:41.661722Z",
     "iopub.status.busy": "2026-01-23T18:34:41.661072Z",
     "iopub.status.idle": "2026-01-23T18:34:41.674289Z",
     "shell.execute_reply": "2026-01-23T18:34:41.673549Z"
    },
    "papermill": {
     "duration": 0.118513,
     "end_time": "2026-01-23T18:34:41.675824",
     "exception": false,
     "start_time": "2026-01-23T18:34:41.557311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "\n",
    "class ComputeMetrics(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComputeMetrics, self).__init__()\n",
    "        self.dice_metric = DiceMetric(reduction=\"mean_batch\")\n",
    "        self.hausdorff_metric = HausdorffDistanceMetric(percentile=95.0, reduction=\"mean_batch\")\n",
    "\n",
    "    def compute(self, p, y, lbl):\n",
    "        self.dice_metric.reset()\n",
    "        self.hausdorff_metric.reset()\n",
    "        \n",
    "        print(f\"{lbl} - Prediction unique values: {torch.unique(p)}\")\n",
    "        print(f\"{lbl} - Ground truth unique values: {torch.unique(y)}\")\n",
    "\n",
    "        if torch.sum(y.float()) == 0 and torch.sum(p.float()) == 0:  # True Negative Case: No foreground pixels in GT\n",
    "            print(f\"{lbl} - No positive samples in ground truth.\")\n",
    "            print(f\"Dice scores for {lbl} for this batch: {1.0}\")\n",
    "            print(f\"Hausdorff distances for {lbl} for this batch: {0.0}\")\n",
    "            return torch.tensor(1.0), torch.tensor(0.0)\n",
    "        \n",
    "        if torch.sum(p.float()) == 0 and torch.sum(y.float()) > 0:  # False Negative Case: GT has 1s, Prediction is all 0s\n",
    "            print(f\"{lbl} - False Negative Case: GT has positive samples, but prediction is empty.\")\n",
    "            print(f\"Dice scores for {lbl} for this batch: {0.0}\")\n",
    "            print(f\"Hausdorff distances for {lbl} for this batch: {373.1287}\")\n",
    "            return torch.tensor(0.0), torch.tensor(373.1287)\n",
    "        \n",
    "        if torch.sum(p.float()) > 0 and torch.sum(y.float()) == 0:  # False Positive Case: Prediction has 1s, GT is all 0s\n",
    "            print(f\"{lbl} - False Positive Case: Prediction has positives, but ground truth is empty.\")\n",
    "            print(f\"Dice scores for {lbl} for this batch: {0.0}\")\n",
    "            print(f\"Hausdorff distances for {lbl} for this batch: {373.1287}\")\n",
    "            return torch.tensor(0.0), torch.tensor(373.1287)\n",
    "\n",
    "        # Compute metrics normally\n",
    "        dice_score = self.dice_metric(p.float(), y.float())\n",
    "        hausdorff_dist = self.hausdorff_metric(p.float(), y.float())\n",
    "\n",
    "        print(f\"Dice scores for {lbl} for this batch:\\n {dice_score.item()}\")\n",
    "        print(f\"Hausdorff distances for {lbl} for this batch:\\n{hausdorff_dist.item()}\")\n",
    "    \n",
    "        return dice_score, hausdorff_dist\n",
    "\n",
    "    def forward(self, p, y):\n",
    "        p = (torch.sigmoid(p) > 0.5)\n",
    "        y_wt, y_tc, y_et = y > 0, ((y == 1) + (y == 3)) > 0, y == 3\n",
    "        p_wt, p_tc, p_et = p[:, 1].unsqueeze(1), p[:, 2].unsqueeze(1), p[:, 3].unsqueeze(1)\n",
    "        \n",
    "        dice_wt, hd_wt = self.compute(p_wt, y_wt, 'wt')\n",
    "        dice_tc, hd_tc = self.compute(p_tc, y_tc, 'tc')\n",
    "        dice_et, hd_et = self.compute(p_et, y_et, 'et')\n",
    "        \n",
    "        return [dice_wt, hd_wt], [dice_tc, hd_tc], [dice_et, hd_et]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb703941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T18:34:41.882581Z",
     "iopub.status.busy": "2026-01-23T18:34:41.882231Z",
     "iopub.status.idle": "2026-01-23T18:34:41.892552Z",
     "shell.execute_reply": "2026-01-23T18:34:41.891661Z"
    },
    "papermill": {
     "duration": 0.115053,
     "end_time": "2026-01-23T18:34:41.894227",
     "exception": false,
     "start_time": "2026-01-23T18:34:41.779174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_net(model, loader): # student_model, testLoader\n",
    "    torch.manual_seed(0)\n",
    "    model.eval()\n",
    "    n_test_batches = len(loader)\n",
    "\n",
    "    compute_metrics = ComputeMetrics()\n",
    "    total_metrics = {\"WT\": {'dice_score': 0, 'hausdorff_distance': 0},\n",
    "                     \"TC\": {'dice_score': 0, 'hausdorff_distance': 0},\n",
    "                     \"ET\": {'dice_score': 0, 'hausdorff_distance': 0}}\n",
    "\n",
    "    with tqdm(total=n_test_batches, desc='Testing', unit='batch', leave=False) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for step, y in enumerate(loader):\n",
    "                y['imgs'], y['masks']= y['imgs'].to('cuda'), y['masks'].to('cuda')\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    print(\"--------Now patient:\", y['patient_id'])\n",
    "                    output = model(y['imgs'])\n",
    "                    wt_metrics, tc_metrics, et_metrics = compute_metrics(output['pred'], y['masks'])\n",
    "                    \n",
    "                    total_metrics['WT']['dice_score'] += wt_metrics[0].item()\n",
    "                    total_metrics['WT']['hausdorff_distance'] += wt_metrics[1].item()\n",
    "\n",
    "                    total_metrics['TC']['dice_score'] += tc_metrics[0].item()\n",
    "                    total_metrics['TC']['hausdorff_distance'] += tc_metrics[1].item()\n",
    "\n",
    "                    total_metrics['ET']['dice_score'] += et_metrics[0].item()\n",
    "                    total_metrics['ET']['hausdorff_distance'] += et_metrics[1].item()\n",
    "                                    \n",
    "                pbar.update(1)\n",
    "\n",
    "        total_metrics['WT']['dice_score'] /= n_test_batches\n",
    "        total_metrics['WT']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "        total_metrics['TC']['dice_score'] /= n_test_batches\n",
    "        total_metrics['TC']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "        total_metrics['ET']['dice_score'] /= n_test_batches\n",
    "        total_metrics['ET']['hausdorff_distance'] /= n_test_batches\n",
    "\n",
    "\n",
    "        print(\"************************************************************************\")\n",
    "        print(f\"Average Dice Score for WT: {total_metrics['WT']['dice_score']:.4f}\")\n",
    "        print(f\"Average Hausdorff Distance for WT: {total_metrics['WT']['hausdorff_distance']:.4f}\")\n",
    "\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "                                     \n",
    "        print(f\"Average Dice Score for TC: {total_metrics['TC']['dice_score']:.4f}\")\n",
    "        print(f\"Average Hausdorff Distance for TC: {total_metrics['TC']['hausdorff_distance']:.4f}\")\n",
    "                              \n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "        print(\"-----------------------------------------------------------------------------\")\n",
    "                                     \n",
    "        print(f\"Average Dice Score for ET: {total_metrics['ET']['dice_score']:.4f}\")\n",
    "        print(f\"Average Hausdorff Distance for ET: {total_metrics['ET']['hausdorff_distance']:.4f}\")\n",
    "        print(\"************************************************************************\")\n",
    "\n",
    "        model.train()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90e6e3cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T18:34:42.100741Z",
     "iopub.status.busy": "2026-01-23T18:34:42.100315Z",
     "iopub.status.idle": "2026-01-23T18:35:51.108144Z",
     "shell.execute_reply": "2026-01-23T18:35:51.107089Z"
    },
    "papermill": {
     "duration": 69.114024,
     "end_time": "2026-01-23T18:35:51.110424",
     "exception": false,
     "start_time": "2026-01-23T18:34:41.996400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 69\n",
      "Number of validation samples 9\n",
      "Number of testing samples 21\n",
      "Found model: /kaggle/input/ped-hybrid/Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth\n",
      "Loaded model: /kaggle/input/ped-hybrid/Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/21 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning:\n",
      "\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Now patient: ['BraTS-PED-00006-000']\n",
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 1/21 [00:04<01:27,  4.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores for wt for this batch:\n",
      " 0.5027614235877991\n",
      "Hausdorff distances for wt for this batch:\n",
      "45.39823913574219\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.5302520394325256\n",
      "Hausdorff distances for tc for this batch:\n",
      "45.09988784790039\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.6775348782539368\n",
      "Hausdorff distances for et for this batch:\n",
      "38.65099334716797\n",
      "--------Now patient: ['BraTS-PED-00010-000']\n",
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8293468952178955\n",
      "Hausdorff distances for wt for this batch:\n",
      "5.4772257804870605\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.8048547506332397\n",
      "Hausdorff distances for tc for this batch:\n",
      "5.385164737701416\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  10%|▉         | 2/21 [00:05<00:43,  2.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores for et for this batch:\n",
      " 0.7887595295906067\n",
      "Hausdorff distances for et for this batch:\n",
      "5.099019527435303\n",
      "--------Now patient: ['BraTS-PED-00026-000']\n",
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8973727226257324\n",
      "Hausdorff distances for wt for this batch:\n",
      "4.242640495300293\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▍        | 3/21 [00:08<00:47,  2.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores for tc for this batch:\n",
      " 0.3901151120662689\n",
      "Hausdorff distances for tc for this batch:\n",
      "16.401220321655273\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.28218841552734375\n",
      "Hausdorff distances for et for this batch:\n",
      "15.65247631072998\n",
      "--------Now patient: ['BraTS-PED-00032-000']\n",
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.7439876198768616\n",
      "Hausdorff distances for wt for this batch:\n",
      "27.459060668945312\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  19%|█▉        | 4/21 [00:09<00:33,  1.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores for tc for this batch:\n",
      " 0.7348026037216187\n",
      "Hausdorff distances for tc for this batch:\n",
      "27.2928524017334\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.0\n",
      "Hausdorff distances for et for this batch:\n",
      "68.6593017578125\n",
      "--------Now patient: ['BraTS-PED-00042-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 5/21 [00:14<00:53,  3.33s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.848588228225708\n",
      "Hausdorff distances for wt for this batch:\n",
      "11.045360565185547\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.7760300636291504\n",
      "Hausdorff distances for tc for this batch:\n",
      "8.871150016784668\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.3634992241859436\n",
      "Hausdorff distances for et for this batch:\n",
      "8.062257766723633\n",
      "--------Now patient: ['BraTS-PED-00061-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▊       | 6/21 [00:15<00:36,  2.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9166417121887207\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.4494898319244385\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9116504192352295\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.8284270763397217\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.5439239740371704\n",
      "Hausdorff distances for et for this batch:\n",
      "7.0\n",
      "--------Now patient: ['BraTS-PED-00062-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 7/21 [00:22<00:55,  4.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8572982549667358\n",
      "Hausdorff distances for wt for this batch:\n",
      "3.464101552963257\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.863214373588562\n",
      "Hausdorff distances for tc for this batch:\n",
      "3.316624879837036\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.03527653217315674\n",
      "Hausdorff distances for et for this batch:\n",
      "11.937281608581543\n",
      "--------Now patient: ['BraTS-PED-00084-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 8/21 [00:23<00:38,  2.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9241234660148621\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.0\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9234143495559692\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.0\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.3519037365913391\n",
      "Hausdorff distances for et for this batch:\n",
      "10.705113410949707\n",
      "--------Now patient: ['BraTS-PED-00086-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  43%|████▎     | 9/21 [00:27<00:38,  3.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9052277207374573\n",
      "Hausdorff distances for wt for this batch:\n",
      "3.7416574954986572\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9012612700462341\n",
      "Hausdorff distances for tc for this batch:\n",
      "4.0\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.0\n",
      "Hausdorff distances for et for this batch:\n",
      "22.64618492126465\n",
      "--------Now patient: ['BraTS-PED-00087-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 10/21 [00:28<00:26,  2.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9151695370674133\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.2360680103302\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9095808267593384\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.2360680103302\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.3972817659378052\n",
      "Hausdorff distances for et for this batch:\n",
      "10.630146026611328\n",
      "--------Now patient: ['BraTS-PED-00106-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 11/21 [00:29<00:22,  2.27s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8889132738113403\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.4494898319244385\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.8799375295639038\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.8284270763397217\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False], device='cuda:0')\n",
      "et - False Positive Case: Prediction has positives, but ground truth is empty.\n",
      "Dice scores for et for this batch: 0.0\n",
      "Hausdorff distances for et for this batch: 373.1287\n",
      "--------Now patient: ['BraTS-PED-00107-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  57%|█████▋    | 12/21 [00:30<00:16,  1.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9340874552726746\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.2360680103302\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9332037568092346\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.2360680103302\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False], device='cuda:0')\n",
      "et - False Positive Case: Prediction has positives, but ground truth is empty.\n",
      "Dice scores for et for this batch: 0.0\n",
      "Hausdorff distances for et for this batch: 373.1287\n",
      "--------Now patient: ['BraTS-PED-00114-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 13/21 [00:33<00:16,  2.01s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.7826968431472778\n",
      "Hausdorff distances for wt for this batch:\n",
      "7.0\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.7448819875717163\n",
      "Hausdorff distances for tc for this batch:\n",
      "6.418643951416016\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.74113929271698\n",
      "Hausdorff distances for et for this batch:\n",
      "4.123105525970459\n",
      "--------Now patient: ['BraTS-PED-00116-000']\n",
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.7719013690948486\n",
      "Hausdorff distances for wt for this batch:\n",
      "7.0\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 14/21 [00:34<00:11,  1.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice scores for tc for this batch:\n",
      " 0.6168429255485535\n",
      "Hausdorff distances for tc for this batch:\n",
      "7.8102498054504395\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.06316029280424118\n",
      "Hausdorff distances for et for this batch:\n",
      "13.747727394104004\n",
      "--------Now patient: ['BraTS-PED-00120-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████▏  | 15/21 [00:38<00:15,  2.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.5794209837913513\n",
      "Hausdorff distances for wt for this batch:\n",
      "26.476404190063477\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.6042788624763489\n",
      "Hausdorff distances for tc for this batch:\n",
      "25.061904907226562\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.643264889717102\n",
      "Hausdorff distances for et for this batch:\n",
      "5.099019527435303\n",
      "--------Now patient: ['BraTS-PED-00126-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 16/21 [00:39<00:09,  1.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8347014784812927\n",
      "Hausdorff distances for wt for this batch:\n",
      "3.7416574954986572\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.8472320437431335\n",
      "Hausdorff distances for tc for this batch:\n",
      "3.605551242828369\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.4290657341480255\n",
      "Hausdorff distances for et for this batch:\n",
      "6.77862024307251\n",
      "--------Now patient: ['BraTS-PED-00130-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  81%|████████  | 17/21 [00:45<00:13,  3.31s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.8137843012809753\n",
      "Hausdorff distances for wt for this batch:\n",
      "23.25940704345703\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.8187810182571411\n",
      "Hausdorff distances for tc for this batch:\n",
      "22.912878036499023\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.012583271600306034\n",
      "Hausdorff distances for et for this batch:\n",
      "26.419689178466797\n",
      "--------Now patient: ['BraTS-PED-00135-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▌ | 18/21 [00:46<00:07,  2.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.6618524789810181\n",
      "Hausdorff distances for wt for this batch:\n",
      "9.486832618713379\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.682170569896698\n",
      "Hausdorff distances for tc for this batch:\n",
      "9.273618698120117\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.0001718803687253967\n",
      "Hausdorff distances for et for this batch:\n",
      "16.5831241607666\n",
      "--------Now patient: ['BraTS-PED-00136-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  90%|█████████ | 19/21 [00:52<00:07,  3.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9046258330345154\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.2360680103302\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.8892773389816284\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.8284270763397217\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False], device='cuda:0')\n",
      "et - False Positive Case: Prediction has positives, but ground truth is empty.\n",
      "Dice scores for et for this batch: 0.0\n",
      "Hausdorff distances for et for this batch: 373.1287\n",
      "--------Now patient: ['BraTS-PED-00140-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 20/21 [00:53<00:02,  2.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.9322981834411621\n",
      "Hausdorff distances for wt for this batch:\n",
      "2.2360680103302\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.9245103001594543\n",
      "Hausdorff distances for tc for this batch:\n",
      "2.2360680103302\n",
      "et - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for et for this batch:\n",
      " 0.3242274820804596\n",
      "Hausdorff distances for et for this batch:\n",
      "7.874007701873779\n",
      "--------Now patient: ['BraTS-PED-00142-000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 21/21 [00:59<00:00,  3.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "wt - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for wt for this batch:\n",
      " 0.7692571878433228\n",
      "Hausdorff distances for wt for this batch:\n",
      "14.456831932067871\n",
      "tc - Prediction unique values: tensor([False,  True], device='cuda:0')\n",
      "tc - Ground truth unique values: tensor([False,  True], device='cuda:0')\n",
      "Dice scores for tc for this batch:\n",
      " 0.7564738392829895\n",
      "Hausdorff distances for tc for this batch:\n",
      "15.0\n",
      "et - Prediction unique values: tensor([False], device='cuda:0')\n",
      "et - Ground truth unique values: tensor([False], device='cuda:0')\n",
      "et - No positive samples in ground truth.\n",
      "Dice scores for et for this batch: 1.0\n",
      "Hausdorff distances for et for this batch: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "Average Dice Score for WT: 0.8197\n",
      "Average Hausdorff Distance for WT: 9.9092\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "Average Dice Score for TC: 0.7830\n",
      "Average Hausdorff Distance for TC: 10.3640\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "Average Dice Score for ET: 0.3169\n",
      "Average Hausdorff Distance for ET: 66.6216\n",
      "************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'workers': 2,\n",
    "    'epochs': 15,\n",
    "    'train_batch_size': 2,\n",
    "    'val_batch_size': 2,\n",
    "    'test_batch_size': 1,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'data_dir': '/kaggle/input/bratsped/Training',\n",
    "    'in_checkpoint_dir': Path('/kaggle/input/ped-hybrid'),\n",
    "    'out_checkpoint_dir': Path('/kaggle/working/')\n",
    "}\n",
    "\n",
    "_, _, testLoader = prepare_data_loaders(args)\n",
    "teacher_path = Path(f'/kaggle/input/ped-hybrid/Teacher_model_after_epoch_25_trainLoss_2.0390_valLoss_1.0664.pth')\n",
    "teacher_model = DynUNet(spatial_dims=3, in_channels=4, out_channels=4, deep_supervision=False).to('cuda')\n",
    "\n",
    "if (teacher_path).is_file():\n",
    "    print(f\"Found model: {teacher_path}\")\n",
    "    ckpt = torch.load(teacher_path, map_location='cuda', weights_only=True)\n",
    "    teacher_model.load_state_dict(ckpt['teacher_model'])\n",
    "    print(f\"Loaded model: {teacher_path}\")\n",
    "    test_net(teacher_model, testLoader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5906271,
     "sourceId": 9666149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9317095,
     "sourceId": 14595764,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3800.391479,
   "end_time": "2026-01-23T18:35:54.038022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-23T17:32:33.646543",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
